{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Lab 2: Probabilistic Reasoning\n",
    "\n",
    "## Explanation/Summarization\n",
    "\n",
    "This lab focuses on **Bayes' theorem** and its applications in probabilistic reasoning and learning algorithms. Key concepts covered include:\n",
    "\n",
    "*   **Conditional probability:** The probability of an event occurring given that another event has already occurred.\n",
    "*   **Bayes' theorem:** A formula that allows us to update the probability of a hypothesis based on new evidence.\n",
    "*   **Chain rule:** A way to calculate the joint probability of multiple events.\n",
    "*   **Prior probability:** The initial probability of an event before considering new evidence.\n",
    "*   **Posterior probability:** The updated probability of an event after considering new evidence.\n",
    "*   **Likelihood:** The probability of observing the evidence given a specific hypothesis.\n",
    "*   **Law of total probability:** A way to calculate the probability of an event by considering all possible ways it can occur.\n",
    "\n",
    "The lab demonstrates how these concepts can be applied to practical problems such as:\n",
    "\n",
    "*   Evaluating learning algorithms.\n",
    "*   Spam filtering.\n",
    "*   Medical diagnosis.\n",
    "\n",
    "## Exercise 1: Rare Disease Test\n",
    "\n",
    "### Description\n",
    "\n",
    "A rare disease affects 1 in 10,000 people. A test for the disease is 99% accurate, meaning:\n",
    "\n",
    "*   If a person has the disease, the test will be positive 99% of the time.\n",
    "*   If a person does not have the disease, the test will be negative 99% of the time.\n",
    "\n",
    "Given that a randomly chosen person tests positive, what is the probability that they actually have the disease?\n",
    "\n",
    "### Code"
   ],
   "id": "124cce815c221cc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T20:25:15.289262Z",
     "start_time": "2025-01-23T20:25:15.285079Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def rare_disease_test():\n",
    "    p_disease = 1 / 10000\n",
    "    p_positive_given_disease = 0.99\n",
    "    p_positive_given_no_disease = 0.01\n",
    "\n",
    "    # P(Positive)\n",
    "    p_positive = (p_positive_given_disease * p_disease) + \\\n",
    "                 (p_positive_given_no_disease * (1 - p_disease))\n",
    "\n",
    "    # P(Disease|Positive)\n",
    "    p_disease_given_positive = (p_positive_given_disease * p_disease) / p_positive\n",
    "    return round(p_disease_given_positive * 100, 2)  # Return percentage\n"
   ],
   "id": "d26f19f5a218a0b0",
   "outputs": [],
   "execution_count": 127
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Exercise 2: Implement a Naive Bayes Spam Filter\n",
    "\n",
    "### Description\n",
    "\n",
    "You are tasked with building an email spam filter using a simplified version of the Naive Bayes' Theorem. You will be given a dataset of emails labeled as \"spam\" or \"not spam\". For each email, a set of common keywords is provided, along with their occurrences. The goal is to classify a new email as spam or not spam based on the words it contains.\n",
    "\n",
    "### Code"
   ],
   "id": "30b92bf9c4d5a17e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T20:25:15.302715Z",
     "start_time": "2025-01-23T20:25:15.295274Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from collections import defaultdict, Counter\n",
    "\n",
    "class NaiveBayesSpamFilter:\n",
    "    def __init__(self):\n",
    "        self.spam_word_counts = defaultdict(int)\n",
    "        self.ham_word_counts = defaultdict(int)\n",
    "        self.spam_emails = 0\n",
    "        self.ham_emails = 0\n",
    "        self.vocabulary = set()\n",
    "\n",
    "    def train(self, emails, labels):\n",
    "        for email, label in zip(emails, labels):\n",
    "            words = email.lower().split()\n",
    "\n",
    "            if label == 'spam':\n",
    "                self.spam_emails += 1\n",
    "                for word in words:\n",
    "                    self.spam_word_counts[word] += 1\n",
    "            else:\n",
    "                self.ham_emails += 1\n",
    "                for word in words:\n",
    "                    self.ham_word_counts[word] += 1\n",
    "\n",
    "            self.vocabulary.update(words)\n",
    "\n",
    "    def calculate_word_probability(self, word, is_spam):\n",
    "        \"\"\"Calculate P(word|spam) or P(word|ham) with Laplace smoothing\"\"\"\n",
    "        if is_spam:\n",
    "            return (self.spam_word_counts[word] + 1) / (self.spam_emails + 2)\n",
    "        return (self.ham_word_counts[word] + 1) / (self.ham_emails + 2)\n",
    "\n",
    "    def classify(self, email):\n",
    "        \"\"\"\n",
    "        Classify a new email as spam or not spam\n",
    "\n",
    "        Args:\n",
    "            email (str): The email text to classify\n",
    "\n",
    "        Returns:\n",
    "            tuple: (classification, spam_probability)\n",
    "        \"\"\"\n",
    "        words = email.lower().split()\n",
    "\n",
    "        # Calculate P(spam) and P(ham)\n",
    "        total_emails = self.spam_emails + self.ham_emails\n",
    "        p_spam = self.spam_emails / total_emails\n",
    "        p_ham = self.ham_emails / total_emails\n",
    "\n",
    "        # Calculate P(words|spam) and P(words|ham)\n",
    "        spam_probability = p_spam\n",
    "        ham_probability = p_ham\n",
    "\n",
    "        for word in words:\n",
    "            if word in self.vocabulary:\n",
    "                spam_probability *= self.calculate_word_probability(word, True)\n",
    "                ham_probability *= self.calculate_word_probability(word, False)\n",
    "\n",
    "        # Normalize probabilities\n",
    "        total_probability = spam_probability + ham_probability\n",
    "        spam_probability = spam_probability / total_probability\n",
    "\n",
    "        return ('spam' if spam_probability > 0.5 else 'not spam', spam_probability)\n",
    "\n",
    "# Example usage\n",
    "def main():\n",
    "    # Training data\n",
    "    training_emails = [\n",
    "        \"win free offer money\",\n",
    "        \"meeting schedule tomorrow project\",\n",
    "        \"free money win big\"\n",
    "    ]\n",
    "    training_labels = ['spam', 'not spam', 'spam']\n",
    "\n",
    "    # Create and train the spam filter\n",
    "    spam_filter = NaiveBayesSpamFilter()\n",
    "    spam_filter.train(training_emails, training_labels)\n",
    "\n",
    "    # Test new email\n",
    "    new_email = \"win free money\"\n",
    "    classification, probability = spam_filter.classify(new_email)\n",
    "\n",
    "    print(f\"Email: '{new_email}'\")\n",
    "    print(f\"Classification: {classification}\")\n",
    "    print(f\"Spam probability: {probability:.2%}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ],
   "id": "fa04e222edac75a4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Email: 'win free money'\n",
      "Classification: spam\n",
      "Spam probability: 95.80%\n"
     ]
    }
   ],
   "execution_count": 128
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Okay, here's the breakdown for Lab 3, structured for a Jupyter Notebook:\n",
    "\n",
    "# Lab 3: Random Variables\n",
    "\n",
    "## Explanation/Summarization\n",
    "\n",
    "This lab introduces the concept of **random variables** as a way to map outcomes from a sample space to numerical values. It covers:\n",
    "\n",
    "*   **Discrete Random Variables:** Variables that take on a countable number of values.\n",
    "    *   **Probability Mass Function (PMF):**  Describes the probability distribution of a discrete random variable.\n",
    "    *   **Expectation (Mean):** The average value of a random variable.\n",
    "    *   **Variance:** A measure of how spread out the values of a random variable are.\n",
    "    *   **Standard Deviation:** The square root of the variance.\n",
    "*   **Continuous Random Variables:** Variables that can take on any value within a given range.\n",
    "    *   **Cumulative Distribution Function (CDF):** Describes the probability that a continuous random variable is less than or equal to a certain value.\n",
    "    *   **Probability Density Function (PDF):**  The derivative of the CDF, used to describe the probability distribution of a continuous random variable.\n",
    "*   **Basic Properties of Random Variables:**\n",
    "    *   Linearity of Expectation: E[aX + b] = aE[X] + b\n",
    "    *   E[g(X)] (for non-linear g)\n",
    "    *   E[X + Y] = E[X] + E[Y]\n",
    "    *   Var(X) = E[X^2] - (E[X])^2\n",
    "    *   Var(aX) = a^2 Var(X)\n",
    "    *   Cov(X, Y) = E[XY] - E[X]E[Y]\n",
    "\n",
    "## Exercise: Covariance Calculation\n",
    "\n",
    "### Description\n",
    "\n",
    "You are a data analyst for an educational institution. You need to analyze the relationship between:\n",
    "\n",
    "1. Student's study hours and their exam scores.\n",
    "2. Student's class attendance and their exam scores.\n",
    "\n",
    "You have data on 20 students, including their study hours, class attendance, and exam scores.\n",
    "\n",
    "Your task is to:\n",
    "\n",
    "*   Calculate the covariance between study hours and exam scores.\n",
    "*   Calculate the covariance between class attendance and exam scores.\n",
    "\n",
    "### Code\n"
   ],
   "id": "31ed979b258e9da3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T20:25:15.326101Z",
     "start_time": "2025-01-23T20:25:15.319098Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Dataset\n",
    "data = {\n",
    "    'Student': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20],\n",
    "    'Study Hours (X)': [5, 3, 6, 4, 8, 5, 7, 6, 4, 8, 9, 5, 7, 6, 5, 6, 7, 8, 5, 7],\n",
    "    'Class Attendance (Y)': [80, 70, 90, 60, 100, 80, 90, 80, 70, 60, 80, 80, 90, 80, 70, 80, 90, 100, 80, 85],\n",
    "    'Exam Score (Z)': [75, 65, 85, 70, 95, 75, 85, 75, 65, 70, 80, 75, 85, 75, 65, 75, 85, 95, 75, 80]\n",
    "}\n",
    "\n",
    "# Dataframe\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Covariance Matrix between Study Hours and Exam Score\n",
    "cov_matrix_XZ = np.cov(df['Study Hours (X)'], df['Exam Score (Z)'])\n",
    "\n",
    "# Extract Covariance\n",
    "cov_XZ = cov_matrix_XZ[0][1]\n",
    "\n",
    "# Covariance Matrix between Class Attendance and Exam Score\n",
    "cov_matrix_YZ = np.cov(df['Class Attendance (Y)'], df['Exam Score (Z)'])\n",
    "\n",
    "# Extract Covariance\n",
    "cov_YZ = cov_matrix_YZ[0][1]\n",
    "\n",
    "# Print\n",
    "print(\"Covariance Matrix between Study Hours and Exam Score\", \"\\n\", cov_matrix_XZ, \"\\n\")\n",
    "print(\"Covariance between Study Hours and Exam Score\", \"\\n\", cov_XZ, \"\\n\")\n",
    "print(\"Covariance Matrix between Class Attendance and Exam Score\", \"\\n\", cov_matrix_YZ, \"\\n\")\n",
    "print(\"Covariance between Class Attendance and Exam Score\", \"\\n\", cov_YZ, \"\\n\")"
   ],
   "id": "83f747f6c98df52a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Covariance Matrix between Study Hours and Exam Score \n",
      " [[ 2.47105263  9.86842105]\n",
      " [ 9.86842105 77.63157895]] \n",
      "\n",
      "Covariance between Study Hours and Exam Score \n",
      " 9.868421052631579 \n",
      "\n",
      "Covariance Matrix between Class Attendance and Exam Score \n",
      " [[121.77631579  88.81578947]\n",
      " [ 88.81578947  77.63157895]] \n",
      "\n",
      "Covariance between Class Attendance and Exam Score \n",
      " 88.8157894736842 \n",
      "\n"
     ]
    }
   ],
   "execution_count": 129
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Lab 4: Bayes-Ball Algorithm\n",
    "\n",
    "## Explanation/Summarization\n",
    "\n",
    "This lab introduces the **Bayes-Ball Algorithm**, a method for determining conditional independence relationships between nodes in a Bayesian Network. Key concepts include:\n",
    "\n",
    "*   **d-separation:** A criterion to check if two nodes are conditionally independent given evidence.\n",
    "*   **Active Path:** A path between two variables is active if they are dependent given the observed evidence.\n",
    "*   **Inactive Path:** A path is inactive if the variables are conditionally independent given the evidence.\n",
    "\n",
    "The algorithm uses the analogy of a ball traversing the network to represent the flow of information. The ball's movement is governed by rules based on arrow directions and whether nodes are observed (evidence).\n",
    "\n",
    "**Rules:**\n",
    "\n",
    "*   **Parent-to-Child (→ B → C):** If B is not observed, the ball can move from B to C and vice-versa.\n",
    "*   **Child-to-Parent (A ← B ← C):** If B is not observed, the ball can move from B to A and vice-versa.\n",
    "*   **Converging Node (Collider) (A → B ← C):**\n",
    "    *   If B or a descendant of B is observed, the path is active, and the ball can pass through.\n",
    "    *   If B is not observed, the path is inactive, and the ball is blocked.\n",
    "\n",
    "## Exercise 1: A and D Independence\n",
    "\n",
    "### Description\n",
    "\n",
    "Consider the following Bayesian network:\n",
    "\n",
    "*   A is a parent of B and C.\n",
    "*   B is a parent of D.\n",
    "*   C is a parent of D.\n",
    "\n",
    "Determine whether variables A and D are independent, given no evidence.\n",
    "\n",
    "### Code"
   ],
   "id": "ec19b78af016a3e1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T20:25:15.350978Z",
     "start_time": "2025-01-23T20:25:15.342412Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from collections import deque\n",
    "\n",
    "#    A\n",
    "#   / \\\n",
    "#  C   B\n",
    "#   \\ /\n",
    "#    D\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.parents = []\n",
    "        self.children = []\n",
    "        self.visited = False\n",
    "\n",
    "def create_bayesian_network():\n",
    "    # Create nodes\n",
    "    nodes = {\n",
    "        \"A\": Node(\"A\"),\n",
    "        \"B\": Node(\"B\"),\n",
    "        \"C\": Node(\"C\"),\n",
    "        \"D\": Node(\"D\")\n",
    "    }\n",
    "\n",
    "    # Establish relationships (A -> B, A -> C, B -> D, C -> D)\n",
    "    nodes[\"A\"].children.extend([nodes[\"B\"], nodes[\"C\"]])\n",
    "    nodes[\"B\"].parents.append(nodes[\"A\"])\n",
    "    nodes[\"C\"].parents.append(nodes[\"A\"])\n",
    "\n",
    "    nodes[\"B\"].children.append(nodes[\"D\"])\n",
    "    nodes[\"C\"].children.append(nodes[\"D\"])\n",
    "    nodes[\"D\"].parents.extend([nodes[\"B\"], nodes[\"C\"]])\n",
    "\n",
    "    return nodes\n",
    "\n",
    "def bayes_ball(start, target, nodes):\n",
    "    queue = deque([(start, \"down\")])  # Start ball from the start node in the down direction\n",
    "    visited = set()\n",
    "\n",
    "    while queue:\n",
    "        current, direction = queue.popleft()\n",
    "\n",
    "        if (current.name, direction) in visited:\n",
    "            continue\n",
    "        visited.add((current.name, direction))\n",
    "\n",
    "        # If we reach the target node, return False (they are dependent)\n",
    "        if current == target:\n",
    "            return False\n",
    "\n",
    "        # Propagate the ball\n",
    "        if direction == \"down\":\n",
    "            # Move to children (if current node is not observed)\n",
    "            for child in current.children:\n",
    "                queue.append((child, \"down\"))\n",
    "            # Move to parents\n",
    "            for parent in current.parents:\n",
    "                queue.append((parent, \"up\"))\n",
    "\n",
    "        elif direction == \"up\":\n",
    "            # Move to parents (if current node is not observed)\n",
    "            for parent in current.parents:\n",
    "                queue.append((parent, \"up\"))\n",
    "            # Move to children\n",
    "            for child in current.children:\n",
    "                queue.append((child, \"down\"))\n",
    "\n",
    "    # If we can't reach the target node, return True (they are independent)\n",
    "    return True\n",
    "\n",
    "def main():\n",
    "    # Create the Bayesian network\n",
    "    nodes = create_bayesian_network()\n",
    "\n",
    "    # Check if A and D are independent using Bayes-Ball algorithm\n",
    "    independent = bayes_ball(nodes[\"A\"], nodes[\"D\"], nodes)\n",
    "\n",
    "    # Output the result\n",
    "    if independent:\n",
    "        print(\"A and D are independent.\")\n",
    "    else:\n",
    "        print(\"A and D are dependent.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "id": "ac4102e486b264e0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A and D are dependent.\n"
     ]
    }
   ],
   "execution_count": 130
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Exercise 2: Cold and Allergy Independence\n",
    "\n",
    "### Description\n",
    "\n",
    "A doctor is diagnosing a patient. The following Bayesian network represents the relationships:\n",
    "\n",
    "*   Cold can cause Sneezing and Fever.\n",
    "*   Allergy can cause Sneezing but not Fever.\n",
    "*   Fever and Sneezing are observed symptoms.\n",
    "\n",
    "Determine whether Cold and Allergy are conditionally independent, given that the patient has Sneezing but no other evidence (like Fever).\n",
    "\n",
    "**Structure:** Cold → Fever, Cold → Sneezing, Allergy → Sneezing.\n",
    "\n",
    "### Code"
   ],
   "id": "1b12a3d6dd030a9d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T20:25:15.550847Z",
     "start_time": "2025-01-23T20:25:15.368907Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from collections import deque\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.parents = []\n",
    "        self.children = []\n",
    "        self.observed = False\n",
    "\n",
    "def create_bayesian_network():\n",
    "    # Create nodes\n",
    "    nodes = {\n",
    "        \"Cold\": Node(\"Cold\"),\n",
    "        \"Allergy\": Node(\"Allergy\"),\n",
    "        \"Sneezing\": Node(\"Sneezing\"),\n",
    "        \"Fever\": Node(\"Fever\")\n",
    "    }\n",
    "\n",
    "    # Establish relationships (Cold -> Fever, Cold -> Sneezing, Allergy -> Sneezing)\n",
    "    nodes[\"Cold\"].children.extend([nodes[\"Fever\"], nodes[\"Sneezing\"]])\n",
    "    nodes[\"Fever\"].parents.append(nodes[\"Cold\"])\n",
    "    nodes[\"Sneezing\"].parents.append(nodes[\"Cold\"])\n",
    "\n",
    "    nodes[\"Allergy\"].children.append(nodes[\"Sneezing\"])\n",
    "    nodes[\"Sneezing\"].parents.append(nodes[\"Allergy\"])\n",
    "\n",
    "    return nodes\n",
    "\n",
    "def bayes_ball(start, target, nodes, observed_nodes):\n",
    "    queue = deque([(start, \"down\")])  # Start ball from the start node in the down direction\n",
    "    visited = set()\n",
    "\n",
    "    # Mark observed nodes\n",
    "    for obs in observed_nodes:\n",
    "        nodes[obs].observed = True\n",
    "\n",
    "    while queue:\n",
    "        current, direction = queue.popleft()\n",
    "\n",
    "        if (current.name, direction) in visited:\n",
    "            continue\n",
    "        visited.add((current.name, direction))\n",
    "\n",
    "        # If we reach the target node, return False (they are dependent)\n",
    "        if current == target:\n",
    "            return False\n",
    "\n",
    "        # Propagate the ball\n",
    "        if direction == \"down\":\n",
    "            # Move to children (if current node is not observed)\n",
    "            if not current.observed:\n",
    "                for child in current.children:\n",
    "                    queue.append((child, \"down\"))\n",
    "            # Move to parents\n",
    "            for parent in current.parents:\n",
    "                queue.append((parent, \"up\"))\n",
    "\n",
    "        elif direction == \"up\":\n",
    "            # If current is a collider and observed, continue propagating\n",
    "            if current.observed:\n",
    "                for child in current.children:\n",
    "                    queue.append((child, \"down\"))\n",
    "            # Move to parents\n",
    "            if not current.observed:\n",
    "                for parent in current.parents:\n",
    "                    queue.append((parent, \"up\"))\n",
    "\n",
    "    # If we can't reach the target node, return True (they are independent)\n",
    "    return True\n",
    "\n",
    "def main():\n",
    "    # Create the Bayesian network\n",
    "    nodes = create_bayesian_network()\n",
    "\n",
    "    # Set \"Sneezing\" as observed\n",
    "    observed_nodes = [\"Sneezing\"]\n",
    "\n",
    "    # Check if Cold and Allergy are independent using Bayes-Ball algorithm\n",
    "    independent = bayes_ball(nodes[\"Cold\"], nodes[\"Allergy\"], nodes, observed_nodes)\n",
    "\n",
    "    # Output the result\n",
    "    if independent:\n",
    "        print(\"Cold and Allergy are independent given Sneezing.\")\n",
    "    else:\n",
    "        print(\"Cold and Allergy are dependent given Sneezing.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "id": "352dc533bbf5bb78",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cold and Allergy are dependent given Sneezing.\n"
     ]
    }
   ],
   "execution_count": 131
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Exercise 3: Server and Database Failure Independence\n",
    "\n",
    "### Description\n",
    "\n",
    "In a distributed system, we have:\n",
    "\n",
    "*   Server failure can cause Application failure.\n",
    "*   Database failure can cause Application failure.\n",
    "*   Network Switch failure can cause both Server and Database failure.\n",
    "\n",
    "Determine whether Server failure and Database failure are conditionally independent given that the Application has failed.\n",
    "\n",
    "### Code"
   ],
   "id": "902afc32ab62fbed"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T20:25:15.571587Z",
     "start_time": "2025-01-23T20:25:15.564207Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from collections import deque\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.parents = []\n",
    "        self.children = []\n",
    "        self.observed = False\n",
    "\n",
    "def create_bayesian_network():\n",
    "    # Create nodes\n",
    "    nodes = {\n",
    "        \"Network Switch Failure\": Node(\"Network Switch Failure\"),\n",
    "        \"Server Failure\": Node(\"Server Failure\"),\n",
    "        \"Database Failure\": Node(\"Database Failure\"),\n",
    "        \"Application Failure\": Node(\"Application Failure\")\n",
    "    }\n",
    "\n",
    "    # Establish relationships\n",
    "    nodes[\"Network Switch Failure\"].children.extend([nodes[\"Server Failure\"], nodes[\"Database Failure\"]])\n",
    "    nodes[\"Server Failure\"].parents.append(nodes[\"Network Switch Failure\"])\n",
    "    nodes[\"Database Failure\"].parents.append(nodes[\"Network Switch Failure\"])\n",
    "\n",
    "    nodes[\"Server Failure\"].children.append(nodes[\"Application Failure\"])\n",
    "    nodes[\"Database Failure\"].children.append(nodes[\"Application Failure\"])\n",
    "    nodes[\"Application Failure\"].parents.extend([nodes[\"Server Failure\"], nodes[\"Database Failure\"]])\n",
    "\n",
    "    return nodes\n",
    "\n",
    "def bayes_ball(start, target, nodes, observed_nodes):\n",
    "    queue = deque([(start, \"down\")])  # Start ball from the start node in the down direction\n",
    "    visited = set()\n",
    "\n",
    "    # Mark observed nodes\n",
    "    for obs in observed_nodes:\n",
    "        nodes[obs].observed = True\n",
    "\n",
    "    while queue:\n",
    "        current, direction = queue.popleft()\n",
    "\n",
    "        if (current.name, direction) in visited:\n",
    "            continue\n",
    "        visited.add((current.name, direction))\n",
    "\n",
    "        # If we reach the target node, return False (they are dependent)\n",
    "        if current == target:\n",
    "            return False\n",
    "\n",
    "        # Propagate the ball\n",
    "        if direction == \"down\":\n",
    "            # Move to children (if current node is not observed)\n",
    "            if not current.observed:\n",
    "                for child in current.children:\n",
    "                    queue.append((child, \"down\"))\n",
    "            # Move to parents\n",
    "            for parent in current.parents:\n",
    "                queue.append((parent, \"up\"))\n",
    "\n",
    "        elif direction == \"up\":\n",
    "            # If current is a collider and observed, continue propagating\n",
    "            if current.observed:\n",
    "                for child in current.children:\n",
    "                    queue.append((child, \"down\"))\n",
    "            # Move to parents\n",
    "            if not current.observed:\n",
    "                for parent in current.parents:\n",
    "                    queue.append((parent, \"up\"))\n",
    "\n",
    "    # If we can't reach the target node, return True (they are independent)\n",
    "    return True\n",
    "\n",
    "def main():\n",
    "    # Create the Bayesian network\n",
    "    nodes = create_bayesian_network()\n",
    "\n",
    "    # Set \"Application Failure\" as observed\n",
    "    observed_nodes = [\"Application Failure\"]\n",
    "\n",
    "    # Check if Server Failure and Database Failure are independent using Bayes-Ball algorithm\n",
    "    independent = bayes_ball(nodes[\"Server Failure\"], nodes[\"Database Failure\"], nodes, observed_nodes)\n",
    "\n",
    "    # Output the result\n",
    "    if independent:\n",
    "        print(\"Server Failure and Database Failure are independent given Application Failure.\")\n",
    "    else:\n",
    "        print(\"Server Failure and Database Failure are dependent given Application Failure.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "id": "3a07ea91923e6b86",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server Failure and Database Failure are dependent given Application Failure.\n"
     ]
    }
   ],
   "execution_count": 132
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Exercise 4: Battery and Fuel System Failure Independence\n",
    "\n",
    "### Description\n",
    "\n",
    "Diagnosing a car that won't start:\n",
    "\n",
    "*   Battery Failure can cause Starter Motor Failure and Ignition System Failure.\n",
    "*   Fuel System Failure can cause Engine Failure.\n",
    "*   Ignition System Failure can cause Engine Failure.\n",
    "*   Starter Motor Failure can cause Engine Failure.\n",
    "*   Engine Failure causes the car to Not Start.\n",
    "\n",
    "Determine whether Battery Failure and Fuel System Failure are conditionally independent given that the Engine has failed.\n",
    "\n",
    "### Code"
   ],
   "id": "a230b9c5ea8a7bc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T20:25:15.590868Z",
     "start_time": "2025-01-23T20:25:15.583035Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from collections import deque\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.parents = []\n",
    "        self.children = []\n",
    "        self.observed = False\n",
    "\n",
    "def create_bayesian_network():\n",
    "    # Create nodes\n",
    "    nodes = {\n",
    "        \"Battery Failure\": Node(\"Battery Failure\"),\n",
    "        \"Starter Motor Failure\": Node(\"Starter Motor Failure\"),\n",
    "        \"Ignition System Failure\": Node(\"Ignition System Failure\"),\n",
    "        \"Fuel System Failure\": Node(\"Fuel System Failure\"),\n",
    "        \"Engine Failure\": Node(\"Engine Failure\"),\n",
    "        \"Not Start\": Node(\"Not Start\")\n",
    "    }\n",
    "\n",
    "    # Establish relationships\n",
    "    nodes[\"Battery Failure\"].children.extend([nodes[\"Starter Motor Failure\"], nodes[\"Ignition System Failure\"]])\n",
    "    nodes[\"Starter Motor Failure\"].parents.append(nodes[\"Battery Failure\"])\n",
    "    nodes[\"Ignition System Failure\"].parents.append(nodes[\"Battery Failure\"])\n",
    "\n",
    "    nodes[\"Starter Motor Failure\"].children.append(nodes[\"Engine Failure\"])\n",
    "    nodes[\"Ignition System Failure\"].children.append(nodes[\"Engine Failure\"])\n",
    "    nodes[\"Fuel System Failure\"].children.append(nodes[\"Engine Failure\"])\n",
    "    nodes[\"Engine Failure\"].parents.extend(\n",
    "        [nodes[\"Starter Motor Failure\"], nodes[\"Ignition System Failure\"], nodes[\"Fuel System Failure\"]])\n",
    "\n",
    "    nodes[\"Engine Failure\"].children.append(nodes[\"Not Start\"])\n",
    "    nodes[\"Not Start\"].parents.append(nodes[\"Engine Failure\"])\n",
    "\n",
    "    return nodes\n",
    "\n",
    "def bayes_ball(start, target, nodes, observed_nodes):\n",
    "    queue = deque([(start, \"down\")])  # Start ball from the start node in the down direction\n",
    "    visited = set()\n",
    "\n",
    "    # Mark observed nodes\n",
    "    for obs in observed_nodes:\n",
    "        nodes[obs].observed = True\n",
    "\n",
    "    while queue:\n",
    "        current, direction = queue.popleft()\n",
    "\n",
    "        if (current.name, direction) in visited:\n",
    "            continue\n",
    "        visited.add((current.name, direction))\n",
    "\n",
    "        # If we reach the target node, return False (they are dependent)\n",
    "        if current == target:\n",
    "            return False\n",
    "\n",
    "        # Propagate the ball\n",
    "        if direction == \"down\":\n",
    "            # Move to children (if current node is not observed)\n",
    "            if not current.observed:\n",
    "                for child in current.children:\n",
    "                    queue.append((child, \"down\"))\n",
    "            # Move to parents\n",
    "            for parent in current.parents:\n",
    "                queue.append((parent, \"up\"))\n",
    "\n",
    "        elif direction == \"up\":\n",
    "            # If current is a collider and observed, continue propagating\n",
    "            if current.observed:\n",
    "                for child in current.children:\n",
    "                    queue.append((child, \"down\"))\n",
    "            # Move to parents\n",
    "            if not current.observed:\n",
    "                for parent in current.parents:\n",
    "                    queue.append((parent, \"up\"))\n",
    "\n",
    "    # If we can't reach the target node, return True (they are independent)\n",
    "    return True\n",
    "\n",
    "def main():\n",
    "    # Create the Bayesian network\n",
    "    nodes = create_bayesian_network()\n",
    "\n",
    "    # Set \"Engine Failure\" as observed\n",
    "    observed_nodes = [\"Engine Failure\"]\n",
    "\n",
    "    # Check if Battery Failure and Fuel System Failure are independent using Bayes-Ball algorithm\n",
    "    independent = bayes_ball(nodes[\"Battery Failure\"], nodes[\"Fuel System Failure\"], nodes, observed_nodes)\n",
    "\n",
    "    # Output the result\n",
    "    if independent:\n",
    "        print(\"Battery Failure and Fuel System Failure are independent given Engine Failure.\")\n",
    "    else:\n",
    "        print(\"Battery Failure and Fuel System Failure are dependent given Engine Failure.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "id": "edfb452c64d45f59",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Battery Failure and Fuel System Failure are dependent given Engine Failure.\n"
     ]
    }
   ],
   "execution_count": 133
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Exercise 5: Study Habits and Motivation Independence\n",
    "\n",
    "### Description\n",
    "\n",
    "Diagnosing a student's learning outcomes:\n",
    "\n",
    "*   Study Habits, Learning Resources and Motivation influence Understanding of Concepts.\n",
    "*   Understanding of Concepts influences Assignments and Exam Performance.\n",
    "*   Exam Anxiety influences Exam Performance.\n",
    "\n",
    "Determine if Study Habits and Motivation are conditionally independent given that the student failed the exam (Exam Performance).\n",
    "\n",
    "### Code"
   ],
   "id": "ee3774de2680f214"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T20:25:15.610529Z",
     "start_time": "2025-01-23T20:25:15.601874Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from collections import deque\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.parents = []\n",
    "        self.children = []\n",
    "        self.observed = False\n",
    "\n",
    "def create_bayesian_network():\n",
    "    # Create nodes\n",
    "    nodes = {\n",
    "        \"Study Habits\": Node(\"Study Habits\"),\n",
    "        \"Motivation\": Node(\"Motivation\"),\n",
    "        \"Learning Resources\": Node(\"Learning Resources\"),\n",
    "        \"Understanding of Concepts\": Node(\"Understanding of Concepts\"),\n",
    "        \"Assignments\": Node(\"Assignments\"),\n",
    "        \"Exam Anxiety\": Node(\"Exam Anxiety\"),\n",
    "        \"Exam Performance\": Node(\"Exam Performance\")\n",
    "    }\n",
    "\n",
    "    # Establish relationships\n",
    "    nodes[\"Study Habits\"].children.append(nodes[\"Understanding of Concepts\"])\n",
    "    nodes[\"Motivation\"].children.append(nodes[\"Understanding of Concepts\"])\n",
    "    nodes[\"Learning Resources\"].children.append(nodes[\"Understanding of Concepts\"])\n",
    "    nodes[\"Understanding of Concepts\"].parents.extend(\n",
    "        [nodes[\"Study Habits\"], nodes[\"Motivation\"], nodes[\"Learning Resources\"]])\n",
    "\n",
    "    nodes[\"Understanding of Concepts\"].children.extend([nodes[\"Assignments\"], nodes[\"Exam Performance\"]])\n",
    "    nodes[\"Assignments\"].parents.append(nodes[\"Understanding of Concepts\"])\n",
    "    nodes[\"Exam Performance\"].parents.extend([nodes[\"Understanding of Concepts\"], nodes[\"Exam Anxiety\"]])\n",
    "\n",
    "    nodes[\"Exam Anxiety\"].children.append(nodes[\"Exam Performance\"])\n",
    "\n",
    "    return nodes\n",
    "\n",
    "def bayes_ball(start, target, nodes, observed_nodes):\n",
    "    queue = deque([(start, \"down\")])  # Start ball from the start node in the down direction\n",
    "    visited = set()\n",
    "\n",
    "    # Mark observed nodes\n",
    "    for obs in observed_nodes:\n",
    "        nodes[obs].observed = True\n",
    "\n",
    "    while queue:\n",
    "        current, direction = queue.popleft()\n",
    "\n",
    "        if (current.name, direction) in visited:\n",
    "            continue\n",
    "        visited.add((current.name, direction))\n",
    "\n",
    "        # If we reach the target node, return False (they are dependent)\n",
    "        if current == target:\n",
    "            return False\n",
    "\n",
    "        # Propagate the ball\n",
    "        if direction == \"down\":\n",
    "            # Move to children (if current node is not observed)\n",
    "            if not current.observed:\n",
    "                for child in current.children:\n",
    "                    queue.append((child, \"down\"))\n",
    "            # Move to parents\n",
    "            for parent in current.parents:\n",
    "                queue.append((parent, \"up\"))\n",
    "\n",
    "        elif direction == \"up\":\n",
    "            # If current is a collider and observed, continue propagating\n",
    "            if current.observed:\n",
    "                for child in current.children:\n",
    "                    queue.append((child, \"down\"))\n",
    "            # Move to parents\n",
    "            if not current.observed:\n",
    "                for parent in current.parents:\n",
    "                    queue.append((parent, \"up\"))\n",
    "\n",
    "    # If we can't reach the target node, return True (they are independent)\n",
    "    return True\n",
    "\n",
    "def main():\n",
    "    # Create the Bayesian network\n",
    "    nodes = create_bayesian_network()\n",
    "\n",
    "    # Set \"Exam Performance\" as observed\n",
    "    observed_nodes = [\"Exam Performance\"]\n",
    "\n",
    "    # Check if Study Habits and Motivation are independent using Bayes-Ball algorithm\n",
    "    independent = bayes_ball(nodes[\"Study Habits\"], nodes[\"Motivation\"], nodes, observed_nodes)\n",
    "\n",
    "    # Output the result\n",
    "    if independent:\n",
    "        print(\"Study Habits and Motivation are independent given Exam Performance.\")\n",
    "    else:\n",
    "        print(\"Study Habits and Motivation are dependent given Exam Performance.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "id": "6ef43b9320379b38",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Study Habits and Motivation are dependent given Exam Performance.\n"
     ]
    }
   ],
   "execution_count": 134
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Lab 5: Bayesian Networks - Exact Inference\n",
    "\n",
    "## Explanation/Summarization\n",
    "\n",
    "This lab focuses on **exact inference** in Bayesian Networks. The key concepts covered are:\n",
    "\n",
    "1. **Calculation of the probability of an observation:** Determining the probability of a specific observation given the values of all nodes in the network.\n",
    "2. **Calculation of marginal probabilities:** Computing the probability of a variable taking a specific value, summing over all possible values of other variables.\n",
    "3. **Enumeration Inference:** An algorithm for exact inference that computes any query by summing the products of conditional probabilities from the Conditional Probability Tables (CPTs).\n",
    "4. **Variable Elimination (Optional):** A more efficient algorithm for exact inference that avoids redundant calculations by strategically ordering the summations.\n",
    "\n",
    "**Steps in Enumeration Inference:**\n",
    "\n",
    "1. **Identify Variable Types:**\n",
    "    *   **Query Variable (Q):** The variable we want to find the probability distribution for.\n",
    "    *   **Evidence Variables (e):** Variables with observed values.\n",
    "    *   **Hidden Variables (Y):** Variables not in the query and not observed.\n",
    "\n",
    "2. **Summing over Markovian Factorization:** Express the query as a sum of joint probabilities: Σ<sub>y∈Y</sub> P(Q, e, y)\n",
    "\n",
    "3. **(Optional) Optimizing Order:** Rearrange the summation to reduce the number of calculations.\n",
    "\n",
    "4. **Compute Sum of Products:** Calculate the joint probabilities based on the CPTs.\n",
    "\n",
    "5. **Normalize:** Divide the resulting probabilities by the sum of all probabilities to get a valid probability distribution.\n",
    "\n",
    "## Exercise 1: Traffic Congestion Prediction\n",
    "\n",
    "### Description\n",
    "\n",
    "A city wants to predict traffic congestion based on weather, events, and accidents. The Bayesian Network is defined as follows:\n",
    "\n",
    "**Environmental Factors:**\n",
    "\n",
    "*   **Weather (W):** W=True (raining), W=False (clear)\n",
    "*   **Event (E):** E=True (major event), E=False (no event)\n",
    "\n",
    "**Traffic Conditions:**\n",
    "\n",
    "*   **Accident (A):** A=True (accident), A=False (no accident)\n",
    "\n",
    "**Congestion:**\n",
    "\n",
    "*   **Congestion (C):** C=True (congestion), C=False (no congestion)\n",
    "\n",
    "**Relationships:**\n",
    "\n",
    "*   W influences A\n",
    "*   E influences C\n",
    "*   A influences C\n",
    "\n",
    "**Goal:**\n",
    "\n",
    "Calculate the probability of traffic congestion (C=True) given that it is raining (W=True) and there is a major event (E=True).\n",
    "\n",
    "**Probability Tables are read from the input data.**\n",
    "\n",
    "### Code"
   ],
   "id": "602d53ac95131d2a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T20:25:15.627850Z",
     "start_time": "2025-01-23T20:25:15.622673Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Drawing of Bayesian Network\n",
    "\n",
    "# W---->A---->C<----E\n",
    "\n",
    "class BayesianNetwork:\n",
    "    def __init__(self, cpt):\n",
    "        # Initialize the Bayesian Network with Conditional Probability Tables (CPT).\n",
    "        self.cpt = cpt\n",
    "\n",
    "    def probability_of_congestion(self, evidence):\n",
    "        # Calculate P(C=True | W=True, E=True)\n",
    "        # Extract the necessary probabilities from the CPT\n",
    "        P_W = self.cpt.get('P(W=True)', 0)\n",
    "        P_E = self.cpt.get('P(E=True)', 0)\n",
    "        P_A_given_W = self.cpt.get(f'P(A=True|W={evidence[\"W\"]})', 0)\n",
    "\n",
    "        P_C_given_E_A = self.cpt.get(f'P(C=True|E={evidence[\"E\"]},A=True)', 0)\n",
    "        P_C_given_E_not_A = self.cpt.get(f'P(C=True|E={evidence[\"E\"]},A=False)', 0)\n",
    "\n",
    "        # Calculate the probability of an accident occurring\n",
    "        P_A = P_A_given_W\n",
    "\n",
    "        # Calculate the probability of C=True given evidence\n",
    "        P_C = P_A * P_C_given_E_A + (1 - P_A) * P_C_given_E_not_A\n",
    "        return P_C\n",
    "\n",
    "# Example CPT data\n",
    "cpt_data = {\n",
    "    \"P(W=True)\": 0.3,\n",
    "    \"P(E=True)\": 0.2,\n",
    "    \"P(A=True|W=True)\": 0.6,\n",
    "    \"P(A=True|W=False)\": 0.1,\n",
    "    \"P(C=True|E=True,A=True)\": 0.9,\n",
    "    \"P(C=True|E=True,A=False)\": 0.7,\n",
    "    \"P(C=True|E=False,A=True)\": 0.5,\n",
    "    \"P(C=True|E=False,A=False)\": 0.2\n",
    "}\n",
    "\n",
    "# Define evidence: it's raining and there's a major event in the city\n",
    "evidence = {\n",
    "    \"W\": True,\n",
    "    \"E\": True\n",
    "}\n",
    "\n",
    "# Initialize the Bayesian Network with the loaded CPT\n",
    "bn = BayesianNetwork(cpt_data)\n",
    "\n",
    "# Calculate the probability of congestion given the evidence\n",
    "probability_congestion = bn.probability_of_congestion(evidence)\n",
    "print(f\"Probability of Congestion given that it is raining and there is a major event: {probability_congestion:.2f}\")"
   ],
   "id": "9ee3c63d3bf2761a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of Congestion given that it is raining and there is a major event: 0.82\n"
     ]
    }
   ],
   "execution_count": 135
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Exercise 2: Student Admission Prediction\n",
    "\n",
    "### Description\n",
    "\n",
    "A university uses a probabilistic model to predict student admissions based on:\n",
    "\n",
    "*   **IQ Level (I):** i<sup>0</sup> (low), i<sup>1</sup> (high)\n",
    "*   **Exam Difficulty (E):** e<sup>0</sup> (easy), e<sup>1</sup> (difficult)\n",
    "*   **Marks (M):** m<sup>0</sup> (low), m<sup>1</sup> (high)\n",
    "*   **Aptitude Score (S):** s<sup>0</sup> (low), s<sup>1</sup> (high)\n",
    "*   **Admission (A):** a<sup>0</sup> (not admitted), a<sup>1</sup> (admitted)\n",
    "\n",
    "**Relationships:**\n",
    "\n",
    "*   I and E influence M\n",
    "*   I influences S\n",
    "*   M influences A\n",
    "\n",
    "**Goal:**\n",
    "\n",
    "Calculate the probability of admission (A=a<sup>1</sup>) given high IQ (I=i<sup>1</sup>), high aptitude score (S=s<sup>1</sup>), and a difficult exam (E=e<sup>1</sup>).\n",
    "\n",
    "**Probability Tables are read from the input data.**\n",
    "\n",
    "### Code"
   ],
   "id": "dc3a3e0e949b4120"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T20:25:15.647167Z",
     "start_time": "2025-01-23T20:25:15.640934Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class BayesianNetwork:\n",
    "    def __init__(self, cpt):\n",
    "        # Initialize the Bayesian Network with Conditional Probability Tables (CPT).\n",
    "\n",
    "        self.cpt = cpt\n",
    "\n",
    "    def probability_of_admission(self, evidence):\n",
    "        # Calculate P(A=a^1 | I=i^1, S=s^1, E=e^1)\n",
    "        # Extract the necessary probabilities from the CPT\n",
    "        P_E = self.cpt.get('P(E=e^1)', 0.3)\n",
    "        P_I = self.cpt.get('P(I=i^1)', 0.2)\n",
    "        P_S_given_I = self.cpt.get(f'P(S=s^1|I=i^1)', 0.6)\n",
    "\n",
    "        # Get P(M|I, E) values for the given evidence\n",
    "        P_M0_given_I_E = self.cpt.get(f'P(M=m^0|I=i^1,E=e^1)', 0.8)\n",
    "        P_M1_given_I_E = self.cpt.get(f'P(M=m^1|I=i^1,E=e^1)', 0.2)\n",
    "\n",
    "        # Get P(A|M) values\n",
    "        P_A1_given_M0 = self.cpt.get(f'P(A=a^1|M=m^0)', 0.1)\n",
    "        P_A1_given_M1 = self.cpt.get(f'P(A=a^1|M=m^1)', 0.1)\n",
    "\n",
    "        # Calculate the joint probability for M and A\n",
    "        P_A1 = P_M0_given_I_E * P_A1_given_M0 + P_M1_given_I_E * P_A1_given_M1\n",
    "\n",
    "        # Calculate the final probability P(A=a^1 | I=i^1, S=s^1, E=e^1)\n",
    "        probability_admission = P_I * P_S_given_I * P_E * P_A1\n",
    "        return probability_admission\n",
    "\n",
    "# Example CPT data\n",
    "cpt_data = {\n",
    "    \"P(E=e^0)\": 0.7, \"P(E=e^1)\": 0.3,\n",
    "    \"P(I=i^0)\": 0.8, \"P(I=i^1)\": 0.2,\n",
    "    \"P(S=s^0|I=i^0)\": 0.75, \"P(S=s^1|I=i^0)\": 0.25,\n",
    "    \"P(S=s^0|I=i^1)\": 0.4, \"P(S=s^1|I=i^1)\": 0.6,\n",
    "    \"P(M=m^0|I=i^0,E=e^0)\": 0.6, \"P(M=m^1|I=i^0,E=e^0)\": 0.4,\n",
    "    \"P(M=m^0|I=i^0,E=e^1)\": 0.9, \"P(M=m^1|I=i^0,E=e^1)\": 0.1,\n",
    "    \"P(M=m^0|I=i^1,E=e^0)\": 0.5, \"P(M=m^1|I=i^1,E=e^0)\": 0.5,\n",
    "    \"P(M=m^0|I=i^1,E=e^1)\": 0.8, \"P(M=m^1|I=i^1,E=e^1)\": 0.2,\n",
    "    \"P(A=a^0|M=m^0)\": 0.6, \"P(A=a^1|M=m^0)\": 0.4,\n",
    "    \"P(A=a^0|M=m^1)\": 0.9, \"P(A=a^1|M=m^1)\": 0.1\n",
    "}\n",
    "\n",
    "# Define the evidence: High IQ, High Aptitude Score, Difficult Exam\n",
    "evidence = {\n",
    "    \"I\": \"i^1\",\n",
    "    \"S\": \"s^1\",\n",
    "    \"E\": \"e^1\"\n",
    "}\n",
    "\n",
    "# Initialize the Bayesian Network with the loaded CPT\n",
    "bn = BayesianNetwork(cpt_data)\n",
    "\n",
    "# Calculate the probability of admission given the evidence\n",
    "probability_admission = bn.probability_of_admission(evidence)\n",
    "print(f\"Probability of Admission given high IQ, high aptitude score, and difficult exam: {probability_admission:.2f}\")"
   ],
   "id": "eefa347c579bf5c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of Admission given high IQ, high aptitude score, and difficult exam: 0.01\n"
     ]
    }
   ],
   "execution_count": 136
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Lab 6: The Junction Tree Algorithm\n",
    "\n",
    "## Explanation/Summarization\n",
    "\n",
    "This lab focuses on the **Junction Tree Algorithm**, a method for performing exact inference in Bayesian Networks. The algorithm involves the following steps:\n",
    "\n",
    "1. **Moralization:** Convert the directed Bayesian Network into an undirected moral graph by connecting parents of common children and removing edge directions.\n",
    "2. **Triangulation:** Add edges to the moral graph to ensure that every cycle of length four or more has a chord (an edge connecting two non-adjacent nodes in the cycle).\n",
    "3. **Identify Maximal Cliques:** Find the maximal fully connected subgraphs (cliques) in the triangulated graph.\n",
    "4. **Build the Junction Tree:**\n",
    "    *   Connect the maximal cliques to form a junction tree.\n",
    "    *   Use a Maximum Spanning Tree algorithm to connect cliques, with edge weights representing the number of shared variables between cliques.\n",
    "    *   Ensure the **running intersection property (RIP)**: If a variable appears in multiple cliques, those cliques must be connected along a path in the tree.\n",
    "\n",
    "5. **Initialize Potentials:**\n",
    "    *   Assign initial probability distributions (potentials) to each clique and separator (intersection between cliques).\n",
    "    *   Potentials represent the joint probability distribution of variables in each clique.\n",
    "\n",
    "6. **Set Evidence (if applicable):** Incorporate evidence by adjusting potentials in relevant cliques.\n",
    "\n",
    "7. **Run Belief Propagation:**\n",
    "    *   Perform belief propagation (message passing) on the junction tree to calculate marginal probabilities and ensure consistency.\n",
    "    *   **Collect (inward) phase:** Pass messages from leaves to an arbitrarily chosen root.\n",
    "    *   **Distribute (outward) phase:** Pass messages from the root back to the leaves.\n",
    "\n",
    "8. **Query the Junction Tree:** Query any clique for marginal or conditional probabilities after belief propagation is complete.\n",
    "\n",
    "## Exercise: Disaster Response Decision Support System (DR-DSS)\n",
    "\n",
    "### Description\n",
    "\n",
    "A city is developing a DR-DSS to predict critical information during natural disasters. The system uses a Bayesian Network and the Junction Tree Algorithm for fast and accurate real-time predictions.\n",
    "\n",
    "**Nodes:**\n",
    "\n",
    "*   **Disaster Type (D):** Earthquake, Flood, Wildfire\n",
    "*   **Severity (S):** Low, Moderate, High\n",
    "*   **Weather Conditions (W):** Clear, Rain, Windy, Extreme Heat\n",
    "*   **Infrastructure Damage (I):** None, Minor, Major, Severe\n",
    "*   **Risk of Secondary Events (R):** Low, Medium, High\n",
    "*   **Medical Resource Availability (M):** Low, Moderate, High\n",
    "*   **Evacuation Need (E):** Yes, No\n",
    "*   **Communication Reliability (C):** High, Moderate, Low\n",
    "*   **Emergency Response Time (T):** Fast, Moderate, Slow\n",
    "\n",
    "**Relationships:**\n",
    "\n",
    "*   D influences S and R\n",
    "*   S affects I, R, and E\n",
    "*   W impacts R and I\n",
    "*   I influences M, C, and T\n",
    "*   R impacts E\n",
    "*   M, C, and I jointly influence T\n",
    "\n",
    "**Query:**\n",
    "\n",
    "Given an earthquake (D) with high severity (S) and windy weather (W), determine the probability distribution of Emergency Response Time (T) and Evacuation Need (E).\n",
    "\n",
    "### Code\n"
   ],
   "id": "680605a2579cd9f2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T20:25:15.697549Z",
     "start_time": "2025-01-23T20:25:15.686550Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from pgmpy.models import BayesianNetwork\n",
    "from pgmpy.factors.discrete import TabularCPD\n",
    "from pgmpy.inference import VariableElimination\n",
    "\n",
    "def create_disaster_response_network():\n",
    "    model = BayesianNetwork([\n",
    "        ('D', 'S'), ('D', 'R'),\n",
    "        ('S', 'I'), ('S', 'R'), ('S', 'E'),\n",
    "        ('W', 'R'), ('W', 'I'),\n",
    "        ('I', 'M'), ('I', 'C'), ('I', 'T'),\n",
    "        ('R', 'E'),\n",
    "        ('M', 'T'), ('C', 'T')\n",
    "    ])\n",
    "\n",
    "    cpd_d = TabularCPD(variable='D', variable_card=3,\n",
    "        values=[[0.3], [0.4], [0.3]])\n",
    "\n",
    "    cpd_s = TabularCPD(variable='S', variable_card=3,\n",
    "        values=[\n",
    "            [0.6, 0.3, 0.1],\n",
    "            [0.3, 0.4, 0.3],\n",
    "            [0.1, 0.3, 0.6]\n",
    "        ],\n",
    "        evidence=['D'], evidence_card=[3])\n",
    "\n",
    "    cpd_w = TabularCPD(variable='W', variable_card=4,\n",
    "        values=[[0.25], [0.25], [0.25], [0.25]])\n",
    "\n",
    "    cpd_r = TabularCPD(variable='R', variable_card=3,\n",
    "        values=np.ones((3, 36)) * 0.33,  # Fill with uniform probabilities\n",
    "        evidence=['D', 'S', 'W'], evidence_card=[3, 3, 4])\n",
    "\n",
    "    cpd_i = TabularCPD(variable='I', variable_card=4,\n",
    "        values=np.ones((4, 12)) * 0.25,\n",
    "        evidence=['S', 'W'], evidence_card=[3, 4])\n",
    "\n",
    "    cpd_m = TabularCPD(variable='M', variable_card=3,\n",
    "        values=np.ones((3, 4)) * 0.33,\n",
    "        evidence=['I'], evidence_card=[4])\n",
    "\n",
    "    cpd_c = TabularCPD(variable='C', variable_card=3,\n",
    "        values=np.ones((3, 4)) * 0.33,\n",
    "        evidence=['I'], evidence_card=[4])\n",
    "\n",
    "    cpd_e = TabularCPD(variable='E', variable_card=2,\n",
    "        values=np.ones((2, 9)) * 0.5,\n",
    "        evidence=['S', 'R'], evidence_card=[3, 3])\n",
    "\n",
    "    cpd_t = TabularCPD(variable='T', variable_card=3,\n",
    "        values=np.ones((3, 36)) * 0.33,\n",
    "        evidence=['I', 'M', 'C'], evidence_card=[4, 3, 3])\n",
    "\n",
    "    model.add_cpds(cpd_d, cpd_s, cpd_r, cpd_w, cpd_i, cpd_m, cpd_c, cpd_e, cpd_t)\n",
    "\n",
    "    if not model.check_model():\n",
    "        raise ValueError(\"Model is not valid\")\n",
    "\n",
    "    return model\n",
    "\n",
    "def disaster_response_inference():\n",
    "    model = create_disaster_response_network()\n",
    "    inference = VariableElimination(model)\n",
    "    evidence = {'D': 0, 'S': 2, 'W': 2}\n",
    "\n",
    "    print(\"Inference Results:\")\n",
    "    response_time = inference.query(variables=['T'], evidence=evidence)\n",
    "    print(\"\\nEmergency Response Time Probabilities:\")\n",
    "    for idx, prob in enumerate(response_time.values):\n",
    "        print(f\"State {idx}: {prob:.4f}\")\n",
    "\n",
    "    evacuation_need = inference.query(variables=['E'], evidence=evidence)\n",
    "    print(\"\\nEvacuation Need Probabilities:\")\n",
    "    for idx, prob in enumerate(evacuation_need.values):\n",
    "        print(f\"State {idx}: {prob:.4f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    disaster_response_inference()"
   ],
   "id": "b183a38c9886247d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference Results:\n",
      "\n",
      "Emergency Response Time Probabilities:\n",
      "State 0: 0.3333\n",
      "State 1: 0.3333\n",
      "State 2: 0.3333\n",
      "\n",
      "Evacuation Need Probabilities:\n",
      "State 0: 0.5000\n",
      "State 1: 0.5000\n"
     ]
    }
   ],
   "execution_count": 137
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Lab 7: MCMC\n",
    "\n",
    "## Explanation/Summarization\n",
    "\n",
    "This lab introduces **Markov Chain Monte Carlo (MCMC)** methods, a class of algorithms for sampling from probability distributions. MCMC is particularly useful for estimating posterior distributions in Bayesian inference.\n",
    "\n",
    "**Key Concepts:**\n",
    "\n",
    "*   **Markov Chain:** A sequence of events where the probability of each event depends only on the state attained in the previous event.\n",
    "*   **Monte Carlo:** A method that uses random sampling to obtain numerical results.\n",
    "*   **MCMC Idea:**\n",
    "    1. The \"state\" of the network is the current assignment to all variables.\n",
    "    2. Generate the next state by sampling one variable at a time, given its Markov blanket.\n",
    "    3. The process can also involve randomly choosing a variable to sample at each step.\n",
    "\n",
    "*   **Markov Blanket:** The minimal set of variables that makes a specific variable independent of all other variables in the network. It consists of:\n",
    "    *   The variable's parents.\n",
    "    *   The variable's children.\n",
    "    *   The other parents of the variable's children.\n",
    "\n",
    "## Exercise 1: Posterior Distribution using MCMC\n",
    "\n",
    "### Description\n",
    "\n",
    "Determine the posterior distribution for the output current (I<sub>OUT</sub>) using the MCMC method. You are given a Bayesian Network with the following nodes:\n",
    "\n",
    "*   **V<sub>IN</sub>:** Input Voltage (e.g., 220V, 110V)\n",
    "*   **T<sub>AMB</sub>:** Ambient Temperature (e.g., 23°C, 30°C)\n",
    "*   **S<sub>Transformer</sub>:** Transformer State (Working, Defective)\n",
    "*   **S<sub>Rectifier</sub>:** Rectifier State (Working, Defective)\n",
    "*   **V<sub>OUT</sub>:** Output Voltage (e.g., normal, low, high)\n",
    "*   **I<sub>OUT</sub>:** Output Current (e.g., normal, low, high) - **Target variable**\n",
    "*   **OPT:** Overcurrent Protection Triggered (on, off)\n",
    "*   **NL:** Noise Level in Circuit (low, high)\n",
    "*   **OT:** Operating Temperature (e.g., normal, high)\n",
    "\n",
    "The solution should include results for any other observation node. Initial probability values are read from an input file.\n",
    "\n",
    "### Code"
   ],
   "id": "dc5e55f7a36e435e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T20:25:15.990886Z",
     "start_time": "2025-01-23T20:25:15.716966Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "probabilities = {\n",
    "    'VIN': {'220V': 0.8, '110V': 0.2},\n",
    "    'TAMB': {'23C': 0.7, '30C': 0.3},\n",
    "    'STransformer': {'Working': 0.9, 'Defective': 0.1},\n",
    "    'SRectifier': {'Working': 0.85, 'Defective': 0.15},\n",
    "    'VOUT': {'normal': 0.6, 'low': 0.25, 'high': 0.15},\n",
    "    'IOUT': {'normal': 0.5, 'low': 0.3, 'high': 0.2},\n",
    "    'OPT': {'on': 0.4, 'off': 0.6},\n",
    "    'NL': {'low': 0.7, 'high': 0.3},\n",
    "    'OT': {'normal': 0.65, 'high': 0.35}\n",
    "}\n",
    "\n",
    "initial_state = {\n",
    "    'VIN': '220V',\n",
    "    'TAMB': '23C',\n",
    "    'STransformer': 'Working',\n",
    "    'SRectifier': 'Working',\n",
    "    'VOUT': 'normal',\n",
    "    'IOUT': 'normal',\n",
    "    'OPT': 'off',\n",
    "    'NL': 'low',\n",
    "    'OT': 'normal'\n",
    "}\n",
    "\n",
    "def markov_blanket(state, node):\n",
    "    if node == 'IOUT':\n",
    "        return ['VOUT', 'OPT', 'NL', 'OT']\n",
    "    return []\n",
    "\n",
    "def sample_given_blanket(state, node):\n",
    "    if node not in probabilities:\n",
    "        print(f\"Warning: No probabilities found for node '{node}'. Skipping.\")\n",
    "        return state[node]\n",
    "\n",
    "    blanket = markov_blanket(state, node)\n",
    "    node_probabilities = probabilities[node]\n",
    "    values, probs = zip(*node_probabilities.items())\n",
    "    probs = np.array(probs) / np.sum(probs)\n",
    "    return np.random.choice(values, p=probs)\n",
    "\n",
    "def mcmc_sampling(state, target_node, iterations=1000):\n",
    "    samples = {target_node: []}\n",
    "\n",
    "    for _ in range(iterations):\n",
    "        for node in state:\n",
    "            state[node] = sample_given_blanket(state, node)\n",
    "        samples[target_node].append(state[target_node])\n",
    "\n",
    "    unique, counts = np.unique(samples[target_node], return_counts=True)\n",
    "    posterior_distribution = dict(zip(unique, counts / iterations))\n",
    "\n",
    "    return posterior_distribution\n",
    "\n",
    "posterior_iout = mcmc_sampling(initial_state, 'IOUT')\n",
    "posterior_iout_readable = {str(k): float(v) for k, v in posterior_iout.items()}\n",
    "print(\"Posterior distribution for IOUT:\", posterior_iout_readable)"
   ],
   "id": "8aad2516337ebedb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Posterior distribution for IOUT: {'high': 0.173, 'low': 0.317, 'normal': 0.51}\n"
     ]
    }
   ],
   "execution_count": 138
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Exercise 2: Posterior Distribution using Metropolis-Hastings\n",
    "\n",
    "### Description\n",
    "\n",
    "Solve the same problem as in Exercise 1, but this time using the Metropolis-Hastings algorithm.\n",
    "\n",
    "### Code"
   ],
   "id": "60ecef61e6863d74"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T20:25:16.147919Z",
     "start_time": "2025-01-23T20:25:15.997891Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "probabilities = {\n",
    "    'VIN': {'220V': 0.8, '110V': 0.2},\n",
    "    'TAMB': {'23C': 0.7, '30C': 0.3},\n",
    "    'STransformer': {'Working': 0.9, 'Defective': 0.1},\n",
    "    'SRectifier': {'Working': 0.85, 'Defective': 0.15},\n",
    "    'VOUT': {'normal': 0.6, 'low': 0.25, 'high': 0.15},\n",
    "    'IOUT': {'normal': 0.5, 'low': 0.3, 'high': 0.2},\n",
    "    'OPT': {'on': 0.4, 'off': 0.6},\n",
    "    'NL': {'low': 0.7, 'high': 0.3},\n",
    "    'OT': {'normal': 0.65, 'high': 0.35}\n",
    "}\n",
    "\n",
    "initial_state = {\n",
    "    'VIN': '220V',\n",
    "    'TAMB': '23C',\n",
    "    'STransformer': 'Working',\n",
    "    'SRectifier': 'Working',\n",
    "    'VOUT': 'normal',\n",
    "    'IOUT': 'normal',\n",
    "    'OPT': 'off',\n",
    "    'NL': 'low',\n",
    "    'OT': 'normal'\n",
    "}\n",
    "\n",
    "def state_probability(state):\n",
    "    prob = 1.0\n",
    "    for node, value in state.items():\n",
    "        prob *= probabilities[node].get(value, 0.0)\n",
    "    return prob\n",
    "\n",
    "def metropolis_hastings_sampling(state, target_node, iterations=1000):\n",
    "    samples = {target_node: []}\n",
    "\n",
    "    for _ in range(iterations):\n",
    "        for node in state:\n",
    "            current_value = state[node]\n",
    "            current_prob = state_probability(state)\n",
    "\n",
    "            possible_values = list(probabilities[node].keys())\n",
    "            proposed_value = np.random.choice(possible_values)\n",
    "            state[node] = proposed_value\n",
    "\n",
    "            proposed_prob = state_probability(state)\n",
    "\n",
    "            acceptance_ratio = min(1, proposed_prob / current_prob)\n",
    "\n",
    "            if np.random.rand() <= acceptance_ratio:\n",
    "                current_value = proposed_value\n",
    "            else:\n",
    "                state[node] = current_value\n",
    "\n",
    "        samples[target_node].append(state[target_node])\n",
    "\n",
    "    unique, counts = np.unique(samples[target_node], return_counts=True)\n",
    "    posterior_distribution = dict(zip(unique, counts / iterations))\n",
    "\n",
    "    return posterior_distribution\n",
    "\n",
    "posterior_iout = metropolis_hastings_sampling(initial_state, 'IOUT')\n",
    "posterior_iout_readable = {str(k): float(v) for k, v in posterior_iout.items()}\n",
    "print(\"Posterior distribution for IOUT:\", posterior_iout_readable)"
   ],
   "id": "dc2b9b7e20caa88f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Posterior distribution for IOUT: {'high': 0.199, 'low': 0.297, 'normal': 0.504}\n"
     ]
    }
   ],
   "execution_count": 139
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Lab 8: Dynamic Bayesian Networks (DBNs)\n",
    "\n",
    "## Explanation/Summarization\n",
    "\n",
    "This lab introduces **Dynamic Bayesian Networks (DBNs)**, a probabilistic graphical model used to represent systems that evolve over time.\n",
    "\n",
    "**Key Concepts:**\n",
    "\n",
    "*   **Time-Series:** A sequence of observations made sequentially over time.\n",
    "*   **Slices:** Time partitions in a DBN.\n",
    "*   **State Variables (X<sub>t</sub>):** Variables representing the state of the system at time t.\n",
    "*   **Evidence Variables (Y<sub>t</sub>):** Observable variables at time t.\n",
    "*   **Prior Distribution (P(X<sub>0</sub>)):** The initial probability distribution of the state variables.\n",
    "*   **State Transition Model (P(X<sub>t</sub>|X<sub>t-1</sub>)):** Specifies the dependencies between states at different time steps.\n",
    "*   **Observation Model (P(Y<sub>t</sub>|X<sub>t</sub>)):** Specifies the dependencies between observations and state variables at time t.\n",
    "*   **Time-Varying vs. Time-Invariant:** Conditional probabilities can depend on the specific time instance (time-varying) or be constant across time (time-invariant).\n",
    "*   **Unrolling:** A DBN can be transformed into a simple Bayesian Network by unrolling it over time.\n",
    "\n",
    "## Exercise 1: Tree Growth Rings\n",
    "\n",
    "### Description\n",
    "\n",
    "We want to determine the average annual temperature (cold or hot) at a specific location over a sequence of years using tree ring sizes (small, medium, large) as indirect evidence.\n",
    "\n",
    "**Given Information:**\n",
    "\n",
    "*   P(hot<sub>t</sub> | hot<sub>t-1</sub>) = 0.7\n",
    "*   P(cold<sub>t</sub> | cold<sub>t-1</sub>) = 0.6\n",
    "*   **Conditional probability of ring size given temperature:**\n",
    "\n",
    "|          | small | medium | large |\n",
    "| :------- | :---- | :----- | :---- |\n",
    "| **cold** | 0.7   | 0.2    | 0.1   |\n",
    "| **hot**  | 0.1   | 0.4    | 0.5   |\n",
    "\n",
    "*   **Initial state distribution:** (0.6, 0.4)  (P(cold<sub>0</sub>), P(hot<sub>0</sub>))\n",
    "\n",
    "**Task:**\n",
    "\n",
    "Implement a Dynamic Bayesian Network to model this problem and use it to:\n",
    "\n",
    "1. Determine the most likely sequence of temperatures (hot or cold) given a sequence of observed ring sizes.\n",
    "2. Compute the probability distribution over the temperature states (cold and hot) for each time step, given the observed ring sizes.\n",
    "\n",
    "The observations (tree ring sizes) can be loaded from a JSON file named `tree_observations.json`. If the file is not found, use the default observation sequence: `[0, 1, 2, 1, 0]` (representing small, medium, large, medium, small).\n",
    "\n",
    "### Code"
   ],
   "id": "fc4a8da267fa068b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T20:25:16.170710Z",
     "start_time": "2025-01-23T20:25:16.160241Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import json\n",
    "\n",
    "class TreeGrowthRingDBN:\n",
    "    def __init__(self, initial_state_dist, transition_matrix, emission_matrix):\n",
    "        self.initial_state_dist = np.array(initial_state_dist)\n",
    "        self.transition_matrix = np.array(transition_matrix)\n",
    "        self.emission_matrix = np.array(emission_matrix)\n",
    "\n",
    "    def viterbi(self, observations):\n",
    "        T = len(observations)\n",
    "        N = len(self.initial_state_dist)\n",
    "\n",
    "        log_delta = np.zeros((T, N))\n",
    "        log_delta[0] = np.log(self.initial_state_dist) + np.log(self.emission_matrix[:, observations[0]])\n",
    "\n",
    "        psi = np.zeros((T, N), dtype=int)\n",
    "\n",
    "        for t in range(1, T):\n",
    "            for j in range(N):\n",
    "                trans_probs = log_delta[t - 1] + np.log(self.transition_matrix[:, j])\n",
    "                log_delta[t, j] = np.max(trans_probs) + np.log(self.emission_matrix[j, observations[t]])\n",
    "                psi[t, j] = np.argmax(trans_probs)\n",
    "\n",
    "        path = [np.argmax(log_delta[T - 1])]\n",
    "        for t in range(T - 1, 0, -1):\n",
    "            path.insert(0, psi[t, path[0]])\n",
    "\n",
    "        return path\n",
    "\n",
    "    def compute_state_probabilities(self, observations):\n",
    "        T = len(observations)\n",
    "        N = len(self.initial_state_dist)\n",
    "\n",
    "        alpha = np.zeros((T, N))\n",
    "        alpha[0] = self.initial_state_dist * self.emission_matrix[:, observations[0]]\n",
    "        alpha[0] /= np.sum(alpha[0])\n",
    "\n",
    "        for t in range(1, T):\n",
    "            for j in range(N):\n",
    "                alpha[t, j] = np.sum(alpha[t - 1] * self.transition_matrix[:, j]) * self.emission_matrix[\n",
    "                    j, observations[t]]\n",
    "            alpha[t] /= np.sum(alpha[t])\n",
    "\n",
    "        return alpha\n",
    "\n",
    "def load_data(filename):\n",
    "    try:\n",
    "        with open(filename, 'r') as f:\n",
    "            data = json.load(f)\n",
    "        return data['observations']\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Warning: File '{filename}' not found. Using default observations.\")\n",
    "        return None\n",
    "\n",
    "def main():\n",
    "    initial_state_dist = [0.6, 0.4]\n",
    "\n",
    "    transition_matrix = [\n",
    "        [0.6, 0.4],\n",
    "        [0.3, 0.7]\n",
    "    ]\n",
    "\n",
    "    emission_matrix = [\n",
    "        [0.7, 0.2, 0.1],\n",
    "        [0.1, 0.4, 0.5]\n",
    "    ]\n",
    "\n",
    "    dbn = TreeGrowthRingDBN(initial_state_dist, transition_matrix, emission_matrix)\n",
    "\n",
    "    observations = load_data('tree_observations.json')\n",
    "    if observations is None:\n",
    "        observations = [0, 1, 2, 1, 0]  # Default observations if file not found\n",
    "\n",
    "    most_likely_temps = dbn.viterbi(observations)\n",
    "    print(\"Most Likely Temperature Sequence:\",\n",
    "          ['Cold' if t == 0 else 'Hot' for t in most_likely_temps])\n",
    "\n",
    "    state_probs = dbn.compute_state_probabilities(observations)\n",
    "    print(\"\\nState Probabilities:\")\n",
    "    for t, probs in enumerate(state_probs):\n",
    "        print(f\"Time {t}: Cold = {probs[0]:.2f}, Hot = {probs[1]:.2f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "id": "eb4180de1807b50f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: File 'tree_observations.json' not found. Using default observations.\n",
      "Most Likely Temperature Sequence: ['Cold', 'Hot', 'Hot', 'Hot', 'Cold']\n",
      "\n",
      "State Probabilities:\n",
      "Time 0: Cold = 0.91, Hot = 0.09\n",
      "Time 1: Cold = 0.40, Hot = 0.60\n",
      "Time 2: Cold = 0.13, Hot = 0.87\n",
      "Time 3: Cold = 0.20, Hot = 0.80\n",
      "Time 4: Cold = 0.80, Hot = 0.20\n"
     ]
    }
   ],
   "execution_count": 140
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Lab 9: Dynamic Bayesian Networks (cont.)\n",
    "\n",
    "## Explanation/Summarization\n",
    "\n",
    "This lab continues the exploration of **Dynamic Bayesian Networks (DBNs)**, focusing on modeling a robot's navigation in a grid while accounting for dynamic obstacles and uncertain sensor measurements.\n",
    "\n",
    "**The DBN models the following variables:**\n",
    "\n",
    "*   **X<sub>t</sub>:** Robot's position at time t.\n",
    "*   **O<sub>t</sub>:** Obstacle's position at time t.\n",
    "*   **A<sub>t</sub>:** Robot's action at time t (up, down, left, right).\n",
    "*   **Z<sub>t</sub>:** Sensor measurement at time t (close, far).\n",
    "\n",
    "**Key aspects of the problem:**\n",
    "\n",
    "*   **Grid Navigation:** The robot and obstacle move within an NxN grid.\n",
    "*   **Uncertainty:**\n",
    "    *   Robot's movement is probabilistic (e.g., 80% chance of success, 20% chance of staying in place).\n",
    "    *   Obstacle's movement is probabilistic (equal probability of moving to any adjacent cell).\n",
    "    *   Sensor measurements are noisy (probabilities associated with \"close\" and \"far\" based on the relative positions of the robot and obstacle).\n",
    "\n",
    "**Task:**\n",
    "\n",
    "Implement a DBN to model this scenario and perform forward propagation to estimate the probability of the robot being at a specific position (c, l) after k time steps.\n",
    "\n",
    "**Input:**\n",
    "\n",
    "*   Configuration file (`config.txt`) specifying:\n",
    "    *   `N`: Size of the grid (NxN).\n",
    "    *   `c`: Target row.\n",
    "    *   `l`: Target column.\n",
    "    *   `k`: Number of time steps.\n",
    "\n",
    "**Output:**\n",
    "\n",
    "*   Probability of the robot being at position (c, l) after k time steps.\n",
    "*   Probability distribution of the robot's position after k time steps.\n",
    "*   Probability distribution of the obstacle's position after k time steps.\n",
    "\n",
    "## Code"
   ],
   "id": "a48056ce0bf6ea5f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T20:25:16.198184Z",
     "start_time": "2025-01-23T20:25:16.183221Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import random\n",
    "\n",
    "def read_config_file(filename=\"config.txt\"):\n",
    "    \"\"\"Reads configuration from file, default config.txt.\"\"\"\n",
    "    config = {}\n",
    "    try:\n",
    "        with open(filename, 'r') as f:\n",
    "            for line in f:\n",
    "                line = line.strip()\n",
    "                if line and not line.startswith('#'):\n",
    "                    key, value = line.split('=')\n",
    "                    config[key.strip()] = value.strip()\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Configuration file '{filename}' not found. Using default values.\")\n",
    "        return None\n",
    "\n",
    "    n = int(config.get('N', 3))\n",
    "    c = int(config.get('c', 1))\n",
    "    l = int(config.get('l', 2))\n",
    "    k = int(config.get('k', 3))\n",
    "    return n, (c, l), k\n",
    "\n",
    "def get_initial_state(n):\n",
    "    \"\"\"Returns initial robot and obstacle positions and probabilities.\"\"\"\n",
    "    initial_robot_pos = (n // 2 + 1, n // 2 + 1) # Middle of the table, integer division handles both odd and even N\n",
    "    initial_obstacle_pos = (n, n) # Bottom-right corner as default if not specified\n",
    "    robot_prob = {initial_robot_pos: 1.0}\n",
    "    obstacle_prob = {initial_obstacle_pos: 1.0}\n",
    "    return robot_prob, obstacle_prob, initial_robot_pos, initial_obstacle_pos\n",
    "\n",
    "def get_robot_next_pos_prob(current_robot_pos, action, n):\n",
    "    \"\"\"Returns probability distribution of next robot positions given current position and action.\"\"\"\n",
    "    prob_distribution = {}\n",
    "    row, col = current_robot_pos\n",
    "    possible_next_positions = []\n",
    "\n",
    "    if action == 'up':\n",
    "        next_pos = (row - 1, col)\n",
    "    elif action == 'down':\n",
    "        next_pos = (row + 1, col)\n",
    "    elif action == 'left':\n",
    "        next_pos = (row, col - 1)\n",
    "    elif action == 'right':\n",
    "        next_pos = (row, col + 1)\n",
    "    else: # stay\n",
    "        next_pos = (row, col)\n",
    "\n",
    "    # Success move (0.8 probability)\n",
    "    if 1 <= next_pos[0] <= n and 1 <= next_pos[1] <= n: # Check grid boundaries\n",
    "        prob_distribution[next_pos] = prob_distribution.get(next_pos, 0) + 0.8\n",
    "    else:\n",
    "        prob_distribution[current_robot_pos] = prob_distribution.get(current_robot_pos, 0) + 0.8 # Stay in place if move out of bounds\n",
    "\n",
    "    # Failure to move (0.2 probability) - stay in the same position\n",
    "    prob_distribution[current_robot_pos] = prob_distribution.get(current_robot_pos, 0) + 0.2\n",
    "\n",
    "    return prob_distribution\n",
    "\n",
    "def get_obstacle_next_pos_prob(current_obstacle_pos, n):\n",
    "    \"\"\"Returns probability distribution of next obstacle positions given current position.\"\"\"\n",
    "    prob_distribution = {}\n",
    "    row, col = current_obstacle_pos\n",
    "    adjacent_positions = []\n",
    "    for dr, dc in [(0, 1), (0, -1), (1, 0), (-1, 0), (0,0)]: # right, left, down, up, stay\n",
    "        next_pos = (row + dr, col + dc)\n",
    "        if 1 <= next_pos[0] <= n and 1 <= next_pos[1] <= n: # Check grid boundaries\n",
    "            adjacent_positions.append(next_pos)\n",
    "\n",
    "    prob = 1.0 / len(adjacent_positions) if adjacent_positions else 0\n",
    "\n",
    "    for pos in adjacent_positions:\n",
    "        prob_distribution[pos] = prob_distribution.get(pos, 0) + prob\n",
    "\n",
    "    return prob_distribution\n",
    "\n",
    "def get_sensor_prob(robot_pos, obstacle_pos):\n",
    "    \"\"\"Returns probability distribution of sensor measurements given robot and obstacle positions.\"\"\"\n",
    "    sensor_prob = {}\n",
    "    if robot_pos == (2,2) and obstacle_pos == (2,3):\n",
    "        sensor_prob['close'] = 0.7\n",
    "        sensor_prob['far'] = 0.3\n",
    "    elif robot_pos == (2,2) and obstacle_pos == (3,3):\n",
    "        sensor_prob['close'] = 0.3\n",
    "        sensor_prob['far'] = 0.7\n",
    "    elif robot_pos == (1,1) and obstacle_pos == (3,3):\n",
    "        sensor_prob['far'] = 0.9\n",
    "        sensor_prob['close'] = 0.1\n",
    "    else: # Default case if no example matches, assuming \"far\" if not specifically \"close\" cases\n",
    "        sensor_prob['far'] = 0.9\n",
    "        sensor_prob['close'] = 0.1\n",
    "    return sensor_prob\n",
    "\n",
    "def forward_propagation(n, initial_robot_prob, initial_obstacle_prob, actions, observations):\n",
    "    \"\"\"Performs forward propagation for k time steps.\"\"\"\n",
    "    robot_prob_dist = initial_robot_prob\n",
    "    obstacle_prob_dist = initial_obstacle_prob\n",
    "\n",
    "    for t in range(len(actions)):\n",
    "        action = actions[t]\n",
    "        observation = observations[t]\n",
    "\n",
    "        next_robot_prob_dist = {}\n",
    "        next_obstacle_prob_dist = {}\n",
    "\n",
    "        # Predict robot position\n",
    "        for current_robot_pos, robot_prob in robot_prob_dist.items():\n",
    "            robot_next_pos_probs = get_robot_next_pos_prob(current_robot_pos, action, n)\n",
    "            for next_robot_pos, prob in robot_next_pos_probs.items():\n",
    "                next_robot_prob_dist[next_robot_pos] = next_robot_prob_dist.get(next_robot_pos, 0) + robot_prob * prob\n",
    "\n",
    "        # Predict obstacle position\n",
    "        for current_obstacle_pos, obstacle_prob in obstacle_prob_dist.items():\n",
    "            obstacle_next_pos_probs = get_obstacle_next_pos_prob(current_obstacle_pos, n)\n",
    "            for next_obstacle_pos, prob in obstacle_next_pos_probs.items():\n",
    "                next_obstacle_prob_dist[next_obstacle_pos] = next_obstacle_prob_dist.get(next_obstacle_pos, 0) + obstacle_prob * prob\n",
    "\n",
    "        # Incorporate sensor measurement (Observation - Zt) - In this simplified version, we are asked for probability *before* incorporating sensor, so skipping observation update.\n",
    "        robot_prob_dist = next_robot_prob_dist\n",
    "        obstacle_prob_dist = next_obstacle_prob_dist\n",
    "\n",
    "        # Normalize probabilities (important after several steps)\n",
    "        robot_prob_norm_factor = sum(robot_prob_dist.values())\n",
    "        if robot_prob_norm_factor > 0:\n",
    "            robot_prob_dist = {pos: prob / robot_prob_norm_factor for pos, prob in robot_prob_dist.items()}\n",
    "\n",
    "        obstacle_prob_norm_factor = sum(obstacle_prob_dist.values())\n",
    "        if obstacle_prob_norm_factor > 0:\n",
    "            obstacle_prob_dist = {pos: prob / obstacle_prob_norm_factor for pos, prob in obstacle_prob_dist.items()}\n",
    "\n",
    "    return robot_prob_dist, obstacle_prob_dist\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    config_data = read_config_file()\n",
    "    if config_data:\n",
    "        n, target_pos, k = config_data\n",
    "    else:\n",
    "        n, target_pos, k = 3, (1, 2), 3 # Default values if config file not found\n",
    "\n",
    "    initial_robot_prob, initial_obstacle_prob, initial_robot_pos, initial_obstacle_pos = get_initial_state(n)\n",
    "\n",
    "    print(f\"Grid size: {n}x{n}\")\n",
    "    print(f\"Initial robot position: {initial_robot_pos}\")\n",
    "    print(f\"Initial obstacle position: {initial_obstacle_pos}\")\n",
    "    print(f\"Target robot position: {target_pos}\")\n",
    "    print(f\"Time steps: {k}\")\n",
    "\n",
    "    # Example actions (replace with desired sequence of actions for k steps)\n",
    "    actions_sequence = ['up'] * k # Example: Robot tries to move up for k steps\n",
    "    observations_sequence = ['none'] * k # We are not using observations in this simplified forward propagation for prediction.\n",
    "\n",
    "    final_robot_prob_dist, final_obstacle_prob_dist = forward_propagation(n, initial_robot_prob, initial_obstacle_prob, actions_sequence, observations_sequence)\n",
    "\n",
    "    probability_at_target = final_robot_prob_dist.get(target_pos, 0.0)\n",
    "\n",
    "    print(f\"\\nProbability distribution of robot position after {k} time steps:\")\n",
    "    for pos, prob in sorted(final_robot_prob_dist.items()):\n",
    "        print(f\"Position: {pos}, Probability: {prob:.4f}\")\n",
    "\n",
    "    print(f\"\\nProbability distribution of obstacle position after {k} time steps:\")\n",
    "    for pos, prob in sorted(final_obstacle_prob_dist.items()):\n",
    "        print(f\"Position: {pos}, Probability: {prob:.4f}\")\n",
    "\n",
    "    print(f\"\\nProbability of robot being at position {target_pos} after {k} time steps: {probability_at_target:.4f}\")"
   ],
   "id": "94ea51225affe7b2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration file 'config.txt' not found. Using default values.\n",
      "Grid size: 3x3\n",
      "Initial robot position: (2, 2)\n",
      "Initial obstacle position: (3, 3)\n",
      "Target robot position: (1, 2)\n",
      "Time steps: 3\n",
      "\n",
      "Probability distribution of robot position after 3 time steps:\n",
      "Position: (1, 2), Probability: 0.9920\n",
      "Position: (2, 2), Probability: 0.0080\n",
      "\n",
      "Probability distribution of obstacle position after 3 time steps:\n",
      "Position: (1, 2), Probability: 0.0611\n",
      "Position: (1, 3), Probability: 0.0764\n",
      "Position: (2, 1), Probability: 0.0611\n",
      "Position: (2, 2), Probability: 0.1306\n",
      "Position: (2, 3), Probability: 0.2023\n",
      "Position: (3, 1), Probability: 0.0764\n",
      "Position: (3, 2), Probability: 0.2023\n",
      "Position: (3, 3), Probability: 0.1898\n",
      "\n",
      "Probability of robot being at position (1, 2) after 3 time steps: 0.9920\n"
     ]
    }
   ],
   "execution_count": 141
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Lab 10: Causal Networks\n",
    "\n",
    "## Explanation/Summarization\n",
    "\n",
    "This lab focuses on **Causal Networks** (also known as Causal Bayesian Networks), which are graphical models that represent cause-and-effect relationships between variables.\n",
    "\n",
    "**Key Concepts:**\n",
    "\n",
    "*   **Causal Networks:** Directed acyclic graphs where nodes represent variables and directed edges represent causal influences.\n",
    "*   **Correlation vs. Causation:** Causal networks help distinguish between correlation (variables changing together) and causation (one variable directly influencing another).\n",
    "*   **Reichenbach's Common Cause Principle:** If two events A and B are correlated, then either:\n",
    "    1. A causes B.\n",
    "    2. B causes A.\n",
    "    3. There's a common cause C that influences both A and B.\n",
    "\n",
    "## Exercise: Student Performance Prediction\n",
    "\n",
    "### Description\n",
    "\n",
    "The task is to design a system that predicts whether a student will pass or fail a course based on causal relationships between various factors. The goal is to identify struggling students early for intervention.\n",
    "\n",
    "**Factors:**\n",
    "\n",
    "*   **SH (Study Habits):** Good, Average, Poor\n",
    "*   **A (Attendance):** High, Medium, Low\n",
    "*   **MH (Mental Health):** Stable, Moderate, Poor\n",
    "*   **PAP (Prior Academic Performance):** High, Medium, Low\n",
    "*   **ES (External Stressors):** Low, Medium, High\n",
    "*   **Performance:** Pass, Fail (or more granular levels)\n",
    "\n",
    "**Demands:**\n",
    "\n",
    "1. **Define a Causal Bayesian Network (CBN):**\n",
    "    *   Specify the nodes (variables).\n",
    "    *   Define the structure (directed edges representing causal relationships).\n",
    "    *   Provide a qualitative interpretation of the relationships.\n",
    "\n",
    "2. **Identify Struggling Students:**\n",
    "    *   Gather evidence (observed values for some variables).\n",
    "    *   Perform inference on the CBN to estimate the probability of passing or failing.\n",
    "    *   Categorize students into risk groups (e.g., High, Moderate, Low) based on predicted performance.\n",
    "\n",
    "3. **Explain the Adopted Structure:**\n",
    "    *   Justify the causal relationships represented in the CBN.\n",
    "    *   Explain how the desired values (probabilities) could be obtained (e.g., from data, expert knowledge).\n",
    "\n",
    "### Code"
   ],
   "id": "33485e4ed72e767a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T20:25:16.227156Z",
     "start_time": "2025-01-23T20:25:16.213037Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pgmpy.models import BayesianNetwork\n",
    "from pgmpy.factors.discrete import TabularCPD\n",
    "from pgmpy.inference import VariableElimination\n",
    "\n",
    "\n",
    "class StudentPerformanceCBN:\n",
    "    def __init__(self):\n",
    "        # Define the network structure\n",
    "        self.model = BayesianNetwork([\n",
    "            ('PAP', 'SH'),\n",
    "            ('MH', 'A'),\n",
    "            ('ES', 'MH'),\n",
    "            ('SH', 'Performance'),\n",
    "            ('A', 'Performance'),\n",
    "            ('MH', 'Performance'),\n",
    "            ('PAP', 'Performance')\n",
    "        ])\n",
    "\n",
    "        # Create CPDs with correct shape\n",
    "        cpds = [\n",
    "            self._create_cpd('PAP', 3, [[0.3], [0.4], [0.3]]),\n",
    "            self._create_cpd('ES', 3, [[0.4], [0.3], [0.3]]),\n",
    "            self._create_mental_health_cpd(),\n",
    "            self._create_study_habits_cpd(),\n",
    "            self._create_attendance_cpd(),\n",
    "            self._create_performance_cpd()\n",
    "        ]\n",
    "\n",
    "        # Add CPDs to the model\n",
    "        for cpd in cpds:\n",
    "            self.model.add_cpds(cpd)\n",
    "\n",
    "        # Check model consistency\n",
    "        assert self.model.check_model()\n",
    "\n",
    "    def _create_cpd(self, variable, card, values):\n",
    "        return TabularCPD(variable=variable, variable_card=card, values=values)\n",
    "\n",
    "    def _create_mental_health_cpd(self):\n",
    "        return TabularCPD(variable='MH', variable_card=3,\n",
    "                          values=np.array([\n",
    "                              [0.7, 0.3, 0.1],  # Low ES\n",
    "                              [0.2, 0.4, 0.2],  # Medium ES\n",
    "                              [0.1, 0.3, 0.7]  # High ES\n",
    "                          ]),\n",
    "                          evidence=['ES'], evidence_card=[3])\n",
    "\n",
    "    def _create_study_habits_cpd(self):\n",
    "        return TabularCPD(variable='SH', variable_card=3,\n",
    "                          values=np.array([\n",
    "                              [0.7, 0.2, 0.1],  # Low PAP\n",
    "                              [0.2, 0.4, 0.2],  # Medium PAP\n",
    "                              [0.1, 0.4, 0.7]  # High PAP\n",
    "                          ]),\n",
    "                          evidence=['PAP'], evidence_card=[3])\n",
    "\n",
    "    def _create_attendance_cpd(self):\n",
    "        return TabularCPD(variable='A', variable_card=3,\n",
    "                          values=np.array([\n",
    "                              [0.7, 0.2, 0.1],  # Low MH\n",
    "                              [0.2, 0.4, 0.2],  # Medium MH\n",
    "                              [0.1, 0.4, 0.7]  # High MH\n",
    "                          ]),\n",
    "                          evidence=['MH'], evidence_card=[3])\n",
    "\n",
    "    def _create_performance_cpd(self):\n",
    "        # Generate a comprehensive CPD for Performance\n",
    "        performance_values = np.zeros((3, 3 ** 4))\n",
    "\n",
    "        # Iterate through all combinations of SH, A, MH, PAP\n",
    "        for sh in range(3):\n",
    "            for a in range(3):\n",
    "                for mh in range(3):\n",
    "                    for pap in range(3):\n",
    "                        # Calculate index for this combination\n",
    "                        idx = sh * 3 ** 3 + a * 3 ** 2 + mh * 3 + pap\n",
    "\n",
    "                        # Simple logic for performance probability\n",
    "                        if sh == 2 and a == 2 and mh == 2 and pap == 2:\n",
    "                            # Best case\n",
    "                            performance_values[2, idx] = 0.9\n",
    "                            performance_values[1, idx] = 0.1\n",
    "                            performance_values[0, idx] = 0.0\n",
    "                        elif sh == 0 and a == 0 and mh == 0 and pap == 0:\n",
    "                            # Worst case\n",
    "                            performance_values[0, idx] = 0.9\n",
    "                            performance_values[1, idx] = 0.1\n",
    "                            performance_values[2, idx] = 0.0\n",
    "                        else:\n",
    "                            # Middle scenarios\n",
    "                            performance_values[1, idx] = 0.5\n",
    "                            performance_values[0, idx] = 0.3\n",
    "                            performance_values[2, idx] = 0.2\n",
    "\n",
    "        return TabularCPD(variable='Performance', variable_card=3,\n",
    "                          values=performance_values,\n",
    "                          evidence=['SH', 'A', 'MH', 'PAP'],\n",
    "                          evidence_card=[3, 3, 3, 3])\n",
    "\n",
    "    def predict_performance(self, evidence):\n",
    "        inference = VariableElimination(self.model)\n",
    "        return inference.query(variables=['Performance'], evidence=evidence)\n",
    "\n",
    "    def categorize_risk(self, performance_prob):\n",
    "        performance_level = np.argmax(performance_prob.values)\n",
    "        risk_categories = {\n",
    "            0: \"High Risk (Struggling)\",\n",
    "            1: \"Moderate Risk\",\n",
    "            2: \"Low Risk (Excelling)\"\n",
    "        }\n",
    "        return risk_categories[performance_level]\n",
    "\n",
    "\n",
    "def main():\n",
    "    cbn = StudentPerformanceCBN()\n",
    "\n",
    "    scenarios = [\n",
    "        {\n",
    "            'name': 'Student 1',\n",
    "            'evidence': {\n",
    "                'SH': 1, 'A': 0, 'MH': 0, 'PAP': 0, 'ES': 2\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            'name': 'Student 2',\n",
    "            'evidence': {\n",
    "                'SH': 2, 'A': 2, 'MH': 2, 'PAP': 2, 'ES': 0\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    for scenario in scenarios:\n",
    "        print(f\"\\n{scenario['name']} Scenario:\")\n",
    "        performance_query = cbn.predict_performance(scenario['evidence'])\n",
    "        print(\"Performance Probability Distribution:\")\n",
    "        print(performance_query)\n",
    "        risk_category = cbn.categorize_risk(performance_query)\n",
    "        print(f\"Risk Category: {risk_category}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "id": "d0e4202d495fdfa4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Student 1 Scenario:\n",
      "Performance Probability Distribution:\n",
      "+----------------+--------------------+\n",
      "| Performance    |   phi(Performance) |\n",
      "+================+====================+\n",
      "| Performance(0) |             0.3000 |\n",
      "+----------------+--------------------+\n",
      "| Performance(1) |             0.5000 |\n",
      "+----------------+--------------------+\n",
      "| Performance(2) |             0.2000 |\n",
      "+----------------+--------------------+\n",
      "Risk Category: Moderate Risk\n",
      "\n",
      "Student 2 Scenario:\n",
      "Performance Probability Distribution:\n",
      "+----------------+--------------------+\n",
      "| Performance    |   phi(Performance) |\n",
      "+================+====================+\n",
      "| Performance(0) |             0.0000 |\n",
      "+----------------+--------------------+\n",
      "| Performance(1) |             0.1000 |\n",
      "+----------------+--------------------+\n",
      "| Performance(2) |             0.9000 |\n",
      "+----------------+--------------------+\n",
      "Risk Category: Low Risk (Excelling)\n"
     ]
    }
   ],
   "execution_count": 142
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Lab 11: Causal Networks\n",
    "\n",
    "## Explanation/Summarization\n",
    "\n",
    "This lab focuses on **Causal Networks** and **Do-Calculus**, a formal language for discussing causality developed by Judea Pearl.\n",
    "\n",
    "**Key Concepts:**\n",
    "\n",
    "*   **Do-Calculus:** Introduces a new operator, `do()`, to represent actions or interventions in a causal model.\n",
    "*   **`p(y|x)` (Bayesian Conditioning):** Represents the probability of `y` given that `x` is observed.\n",
    "*   **`p(y|do(x))` (Causal Conditioning):** Represents the probability of `y` given that an action is taken to force `x` to a specific value.\n",
    "*   **Goal:** To derive probabilistic formulas for the effects of interventions based on observed probabilities.\n",
    "*   **Notation:**\n",
    "    *   `G`: A graph representing the causal relationships.\n",
    "    *   `W`, `X`, `Y`, `Z`: Disjoint subsets of variables.\n",
    "    *   `G<sub>X</sub>`: The graph `G` with all edges pointing *to* `X` removed.\n",
    "    *   `G<sub>X</sub>`: The graph `G` with all edges pointing *from* `X` removed.\n",
    "    *   `Z(W)`: The set of nodes in `Z` that are not ancestors of `W`.\n",
    "*   **Rules of Do-Calculus:**\n",
    "    1. **Ignoring Observations:**\n",
    "        `p(y|do(x), z, w) = p(y|do(x), w)` if `(Y ⊥ Z | X, W)<sub>G<sub>X</sub></sub>`\n",
    "    2. **Action/Observation Exchange (Back-Door Criterion):**\n",
    "        `p(y|do(x), do(z), w) = p(y|do(x), z, w)` if `(Y ⊥ Z | X, W)<sub>G<sub>X<u>Z</u></sub></sub>`\n",
    "    3. **Ignoring Actions/Interventions:**\n",
    "        `p(y|do(x), do(z), w) = p(y|do(x), w)` if `(Y ⊥ Z | X, W)<sub>G<sub>X, Z(W)</sub></sub>`\n",
    "\n",
    "## Exercise: Impact of Vaccination on Symptoms\n",
    "\n",
    "### Description\n",
    "\n",
    "You are analyzing the impact of a vaccination program on reducing a disease's prevalence. The setup includes:\n",
    "\n",
    "*   **Vaccination (V):** A binary variable (V=1 means vaccinated, V=0 means not vaccinated).\n",
    "*   **Disease (D):** A binary variable (D=1 means the person has the disease, D=0 means they do not).\n",
    "*   **Behavior (B):** A binary variable (B=1 means the person engages in risky behavior, B=0 means they do not).\n",
    "*   **Symptoms (S):** A binary variable (S=1 means symptoms are present, S=0 means they are absent).\n",
    "\n",
    "**Goal:**\n",
    "\n",
    "Determine the causal effect of vaccination (V) on symptoms (S), denoted as P(S|do(V=1)), where do(V=1) implies a hypothetical intervention that forces vaccination regardless of other factors.\n",
    "\n",
    "**Demands:**\n",
    "\n",
    "1. Design an appropriate causal structure.\n",
    "2. Compute P(S|do(V=1)) using the values from the example (on paper).\n",
    "3. Implement the problem using the required probability values read from an input file. (The input file will be embedded in the code).\n",
    "\n",
    "### Code\n"
   ],
   "id": "d6bd898a53164df3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T20:25:16.374748Z",
     "start_time": "2025-01-23T20:25:16.239613Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import json\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from pgmpy.models import BayesianNetwork\n",
    "from pgmpy.factors.discrete import TabularCPD\n",
    "from pgmpy.inference import VariableElimination\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "\n",
    "class CustomerSegmentation:\n",
    "    def __init__(self, n_clusters=2):\n",
    "        self.n_clusters = n_clusters\n",
    "        self.gmm = GaussianMixture(n_components=n_clusters, random_state=42)\n",
    "        self.scaler = StandardScaler()\n",
    "        self.bayesian_network = None\n",
    "\n",
    "        # Embedded data\n",
    "        self.data = {\n",
    "            \"customers\": [\n",
    "                {\"id\": 1, \"X1\": 10, \"X2\": 100, \"Z1\": 25, \"Z2\": 2000},\n",
    "                {\"id\": 2, \"X1\": 12, \"X2\": 120, \"Z1\": 27, \"Z2\": 2500},\n",
    "                {\"id\": 3, \"X1\": 20, \"X2\": 300, \"Z1\": 35, \"Z2\": 4000},\n",
    "                {\"id\": 4, \"X1\": 21, \"X2\": 310, \"Z1\": 36, \"Z2\": 4200},\n",
    "                {\"id\": 5, \"X1\": 30, \"X2\": 500, \"Z1\": 45, \"Z2\": 6000},\n",
    "                {\"id\": 6, \"X1\": 31, \"X2\": 510, \"Z1\": 46, \"Z2\": 6200},\n",
    "                {\"id\": 7, \"X1\": 8, \"X2\": 90, \"Z1\": 22, \"Z2\": 1800},\n",
    "                {\"id\": 8, \"X1\": 9, \"X2\": 110, \"Z1\": 23, \"Z2\": 1900},\n",
    "                {\"id\": 9, \"X1\": 25, \"X2\": 350, \"Z1\": 40, \"Z2\": 5000},\n",
    "                {\"id\": 10, \"X1\": 28, \"X2\": 400, \"Z1\": 42, \"Z2\": 5500}\n",
    "            ]\n",
    "        }\n",
    "\n",
    "    def prepare_data(self):\n",
    "        \"\"\"Prepare data for GMM analysis\"\"\"\n",
    "        X = np.array([[c['X1'], c['X2']] for c in self.data['customers']])\n",
    "        return self.scaler.fit_transform(X)\n",
    "\n",
    "    def fit_gmm(self):\n",
    "        \"\"\"Fit GMM model and return cluster assignments\"\"\"\n",
    "        X = self.prepare_data()\n",
    "        self.clusters = self.gmm.fit_predict(X)\n",
    "        return self.clusters\n",
    "\n",
    "    def setup_bayesian_network(self):\n",
    "        \"\"\"Setup Bayesian Network structure\"\"\"\n",
    "        self.bayesian_network = BayesianNetwork([\n",
    "            ('Z1', 'Cluster'),\n",
    "            ('Z2', 'Cluster')\n",
    "        ])\n",
    "\n",
    "        # Create CPDs\n",
    "        z1_cpd = TabularCPD(\n",
    "            variable='Z1',\n",
    "            variable_card=2,\n",
    "            values=[[0.6], [0.4]]\n",
    "        )\n",
    "\n",
    "        z2_cpd = TabularCPD(\n",
    "            variable='Z2',\n",
    "            variable_card=2,\n",
    "            values=[[0.5], [0.5]]\n",
    "        )\n",
    "\n",
    "        cluster_cpd = TabularCPD(\n",
    "            variable='Cluster',\n",
    "            variable_card=2,\n",
    "            values=[\n",
    "                [0.8, 0.7, 0.3, 0.2],  # Cluster 1 probabilities\n",
    "                [0.2, 0.3, 0.7, 0.8]  # Cluster 2 probabilities\n",
    "            ],\n",
    "            evidence=['Z1', 'Z2'],\n",
    "            evidence_card=[2, 2]\n",
    "        )\n",
    "\n",
    "        self.bayesian_network.add_cpds(z1_cpd, z2_cpd, cluster_cpd)\n",
    "\n",
    "    def compute_cluster_probability(self, z1_val, z2_val):\n",
    "        \"\"\"Compute P(Cluster2|Z1,Z2)\"\"\"\n",
    "        z1_cat = 1 if z1_val >= 35 else 0\n",
    "        z2_cat = 1 if z2_val >= 4000 else 0\n",
    "\n",
    "        inference = VariableElimination(self.bayesian_network)\n",
    "        evidence = {'Z1': z1_cat, 'Z2': z2_cat}\n",
    "        result = inference.query(variables=['Cluster'], evidence=evidence)\n",
    "        return result.values[1]\n",
    "\n",
    "    def visualize_clusters(self):\n",
    "        \"\"\"Visualize the customer segments\"\"\"\n",
    "        X = self.prepare_data()\n",
    "\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        scatter = plt.scatter(X[:, 0], X[:, 1], c=self.clusters, cmap='viridis')\n",
    "        plt.xlabel('Normalized Time on Site')\n",
    "        plt.ylabel('Normalized Purchase Value')\n",
    "        plt.title('Customer Segments')\n",
    "        plt.colorbar(scatter, label='Cluster')\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def main():\n",
    "    # To suppress the joblib warning, set the environment variable\n",
    "    os.environ['LOKY_MAX_CPU_COUNT'] = '4'\n",
    "\n",
    "    # Initialize segmentation\n",
    "    segmentation = CustomerSegmentation()\n",
    "\n",
    "    # Fit GMM and get clusters\n",
    "    clusters = segmentation.fit_gmm()\n",
    "    print(\"\\nGMM Cluster Assignments:\")\n",
    "    for i, cluster in enumerate(clusters, 1):\n",
    "        print(f\"Customer {i}: Cluster {cluster + 1}\")\n",
    "\n",
    "    # Setup and use Bayesian Network\n",
    "    segmentation.setup_bayesian_network()\n",
    "\n",
    "    # Compute P(Cluster2|Z1=35,Z2=4000)\n",
    "    prob = segmentation.compute_cluster_probability(35, 4000)\n",
    "    print(f\"\\nP(Cluster2|Z1=35,Z2=4000) = {prob:.3f}\")\n",
    "\n",
    "    # Visualize the clusters\n",
    "    segmentation.visualize_clusters()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "id": "541d50c1a08b43a5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GMM Cluster Assignments:\n",
      "Customer 1: Cluster 2\n",
      "Customer 2: Cluster 2\n",
      "Customer 3: Cluster 1\n",
      "Customer 4: Cluster 1\n",
      "Customer 5: Cluster 1\n",
      "Customer 6: Cluster 1\n",
      "Customer 7: Cluster 2\n",
      "Customer 8: Cluster 2\n",
      "Customer 9: Cluster 1\n",
      "Customer 10: Cluster 1\n",
      "\n",
      "P(Cluster2|Z1=35,Z2=4000) = 0.800\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 2 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 143
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Okay, I understand. I will proceed with analyzing Lab 12, including the `main.py` code you provided.\n",
    "\n",
    "# Lab 12: EM/GMM\n",
    "\n",
    "## Explanation/Summarization\n",
    "\n",
    "This lab focuses on using **Expectation-Maximization (EM)** and **Gaussian Mixture Models (GMM)** in conjunction with Bayesian Networks to solve a real-world customer segmentation problem.\n",
    "\n",
    "**Key Concepts:**\n",
    "\n",
    "*   **EM Algorithm:** An iterative algorithm for finding maximum likelihood estimates of parameters in statistical models, especially useful when the model depends on unobserved latent variables.\n",
    "*   **GMM:** A probabilistic model that assumes all data points are generated from a mixture of a finite number of Gaussian distributions with unknown parameters.\n",
    "*   **Bayesian Networks:** Directed acyclic graphs that represent probabilistic relationships among a set of variables.\n",
    "\n",
    "**Goal:**\n",
    "\n",
    "Segment customers of an online store based on their purchasing habits (total purchase value) and time spent on the website. Additionally, understand how these segments depend on covariates such as customer age and monthly income.\n",
    "\n",
    "## Exercise: Customer Segmentation for an Online Store\n",
    "\n",
    "### Description\n",
    "\n",
    "An online store wants to segment its customers based on their purchasing habits and time spent on the website to send personalized offers. The marketing manager also wants to understand how these segments depend on customer age and monthly income.\n",
    "\n",
    "**Data:**\n",
    "\n",
    "*   **X1:** Time spent on site (in minutes).\n",
    "*   **X2:** Total purchase value.\n",
    "*   **Z1:** Customer age (covariate).\n",
    "*   **Z2:** Monthly income (covariate).\n",
    "\n",
    "**Clusters:**\n",
    "\n",
    "*   **Cluster 1:** Customers with low purchase values and low time on site.\n",
    "*   **Cluster 2:** Loyal customers with high purchase values and high time on site.\n",
    "\n",
    "**Demands:**\n",
    "\n",
    "1. Design an appropriate structure (presumably a Bayesian Network structure).\n",
    "2. Compute P(Cluster2|Z1=35, Z2=4000) using the values from the example (on paper).\n",
    "3. Implement the problem using EM/GMM and a Bayesian Network structure. The required probability values are read from an input file (which will be embedded in the code).\n",
    "\n",
    "### Code"
   ],
   "id": "5e5d038078de213f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T20:25:16.406267Z",
     "start_time": "2025-01-23T20:25:16.386259Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from scipy.stats import norm\n",
    "os.environ['LOKY_MAX_CPU_COUNT'] = '1'  # Disable core detection warning\n",
    "\n",
    "# Hardcoded input data\n",
    "data = pd.DataFrame({\n",
    "    'Customer': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "    'X1': [10, 12, 20, 21, 30, 31, 8, 9, 25, 28],\n",
    "    'X2': [100, 120, 300, 310, 500, 510, 90, 110, 350, 400],\n",
    "    'Z1': [25, 27, 35, 36, 45, 46, 22, 23, 40, 42],\n",
    "    'Z2': [2000, 2500, 4000, 4200, 6000, 6200, 1800, 1900, 5000, 5500]\n",
    "})\n",
    "\n",
    "# Prepare the features for GMM (X1 and X2)\n",
    "X = data[['X1', 'X2']].values\n",
    "\n",
    "# Fit a GMM with 2 components\n",
    "gmm = GaussianMixture(n_components=2, covariance_type='full')\n",
    "gmm.fit(X)\n",
    "\n",
    "# Assign clusters to each customer\n",
    "clusters = gmm.predict(X)\n",
    "data['Cluster'] = clusters\n",
    "\n",
    "# Determine which cluster corresponds to Cluster1 and Cluster2 based on X1 and X2\n",
    "cluster_means = gmm.means_\n",
    "if cluster_means[0][0] < cluster_means[1][0] and cluster_means[0][1] < cluster_means[1][1]:\n",
    "    # Cluster0 is Cluster1, Cluster1 is Cluster2\n",
    "    data['Cluster'] = data['Cluster'].map({0: 'Cluster1', 1: 'Cluster2'})\n",
    "else:\n",
    "    # Cluster0 is Cluster2, Cluster1 is Cluster1\n",
    "    data['Cluster'] = data['Cluster'].map({0: 'Cluster2', 1: 'Cluster1'})\n",
    "\n",
    "# For each cluster, fit the distribution of Z1 and Z2\n",
    "# Assuming Z1 and Z2 are normally distributed within each cluster\n",
    "\n",
    "# Cluster1\n",
    "cluster1_data = data[data['Cluster'] == 'Cluster1']\n",
    "mu_z1_cluster1 = cluster1_data['Z1'].mean()\n",
    "sigma_z1_cluster1 = cluster1_data['Z1'].var()\n",
    "mu_z2_cluster1 = cluster1_data['Z2'].mean()\n",
    "sigma_z2_cluster1 = cluster1_data['Z2'].var()\n",
    "\n",
    "# Cluster2\n",
    "cluster2_data = data[data['Cluster'] == 'Cluster2']\n",
    "mu_z1_cluster2 = cluster2_data['Z1'].mean()\n",
    "sigma_z1_cluster2 = cluster2_data['Z1'].var()\n",
    "mu_z2_cluster2 = cluster2_data['Z2'].mean()\n",
    "sigma_z2_cluster2 = cluster2_data['Z2'].var()\n",
    "\n",
    "# Compute P(Cluster2 | Z1=35, Z2=4000) using Bayes' theorem\n",
    "# P(Cluster2 | Z1, Z2) = [P(Z1, Z2 | Cluster2) * P(Cluster2)] / P(Z1, Z2)\n",
    "\n",
    "# P(Z1=35 | Cluster2) and P(Z2=4000 | Cluster2)\n",
    "p_z1_given_cluster2 = norm.pdf(35, loc=mu_z1_cluster2, scale=np.sqrt(sigma_z1_cluster2))\n",
    "p_z2_given_cluster2 = norm.pdf(4000, loc=mu_z2_cluster2, scale=np.sqrt(sigma_z2_cluster2))\n",
    "\n",
    "# P(Z1=35 | Cluster1) and P(Z2=4000 | Cluster1)\n",
    "p_z1_given_cluster1 = norm.pdf(35, loc=mu_z1_cluster1, scale=np.sqrt(sigma_z1_cluster1))\n",
    "p_z2_given_cluster1 = norm.pdf(4000, loc=mu_z2_cluster1, scale=np.sqrt(sigma_z2_cluster1))\n",
    "\n",
    "# Prior probabilities\n",
    "p_cluster1 = len(cluster1_data) / len(data)\n",
    "p_cluster2 = len(cluster2_data) / len(data)\n",
    "\n",
    "# P(Z1, Z2)\n",
    "p_z = (p_z1_given_cluster1 * p_z2_given_cluster1 * p_cluster1 +\n",
    "        p_z1_given_cluster2 * p_z2_given_cluster2 * p_cluster2)\n",
    "\n",
    "# P(Cluster2 | Z1, Z2)\n",
    "p_cluster2_given_z = (p_z1_given_cluster2 * p_z2_given_cluster2 * p_cluster2) / p_z\n",
    "\n",
    "print(f\"P(Cluster2 | Z1=35, Z2=4000) = {p_cluster2_given_z:.4f}\")\n",
    "\n",
    "# Gaussian parameters for each cluster's X1 and X2\n",
    "# Cluster1\n",
    "cluster1_X1_mean = cluster1_data['X1'].mean()\n",
    "cluster1_X1_var = cluster1_data['X1'].var()\n",
    "cluster1_X2_mean = cluster1_data['X2'].mean()\n",
    "cluster1_X2_var = cluster1_data['X2'].var()\n",
    "\n",
    "# Cluster2\n",
    "cluster2_X1_mean = cluster2_data['X1'].mean()\n",
    "cluster2_X1_var = cluster2_data['X1'].var()\n",
    "cluster2_X2_mean = cluster2_data['X2'].mean()\n",
    "cluster2_X2_var = cluster2_data['X2'].var()\n",
    "\n",
    "# Print the Gaussian parameters for each cluster\n",
    "print(\"\\nCluster1:\")\n",
    "print(f\"X1 ~ N({cluster1_X1_mean:.2f}, {cluster1_X1_var:.2f})\")\n",
    "print(f\"X2 ~ N({cluster1_X2_mean:.2f}, {cluster1_X2_var:.2f})\")\n",
    "print(\"\\nCluster2:\")\n",
    "print(f\"X1 ~ N({cluster2_X1_mean:.2f}, {cluster2_X1_var:.2f})\")\n",
    "print(f\"X2 ~ N({cluster2_X2_mean:.2f}, {cluster2_X2_var:.2f})\")"
   ],
   "id": "e705219141103bfa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Cluster2 | Z1=35, Z2=4000) = 1.0000\n",
      "\n",
      "Cluster1:\n",
      "X1 ~ N(9.75, 2.92)\n",
      "X2 ~ N(105.00, 166.67)\n",
      "\n",
      "Cluster2:\n",
      "X1 ~ N(25.83, 21.37)\n",
      "X2 ~ N(395.00, 8510.00)\n"
     ]
    }
   ],
   "execution_count": 144
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
